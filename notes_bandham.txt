09/22/2025:

https://pubmed.ncbi.nlm.nih.gov/help/#advanced-search
https://pubmed.ncbi.nlm.nih.gov/help/#finding-full-text
https://pubmed.ncbi.nlm.nih.gov/help/#pt
https://pubmed.ncbi.nlm.nih.gov/?term=covid-19+NOT+preprint%5Bpt%5D

- Take only papers that are only accepted.

reviewed and good journals.

not older than 2015.

Search will have publication date - make sure to use it.

use search api for best use.


10/06/2025:
Qwen 8B
- for small model the prompts has to be consice
- look at musciclaim section: pertrunb 3: there is a prompt.
- musclaim github - human annotation app: read instructions: look at interannotatordata.py
    - it verifies the claim: valid perturbation or not.
    - only new change is generation, not annotation
    - the differentiating condition is mentioned in the file.
- 500 data points: contradictions.: by by qwen model
- 500: nuertral datapoints by swapping firgure names
- we need to finetune it: vlm finetuning: vl2.5
- accuracy test is: small subset that doest go into training - run inference on that with trained model - see what performance.
- Get the total claims number and share it with yash.


10/16/2025:
    - st.text(f”You are given a claim and its perturbation. Your task is to judge whether the perturbation is a contradiction of the original claim. Both the original and perturbed claim cannot be true at the same time.“)
    - “Your task is to perturb the given original claim and produce a contradiction of the original claim. Both the original and perturbed claim cannot be true at the same time.”
    - manually review atleast 50 claims with figures as reference.
    - prepare llm judge for validating perturbated and original claim same as what .py is doing (yash).
    - remove figure reference from the claim text.
    - after judge, we will have two data sets - one all data points (s + p + n) & filtered data with judge.


DID: Used LLM (Qwen8B) for perturbation, for removing fig reference, for judging if the perturbated & original are valid or not.

- Clear the figure reference from the given claim. without changing the meaning at any cost. 

10/15/2025: Part 1 (Generating contradict & neutral data using Qwen)

# Command to start running vllm in the background
nohup python -m vllm.entrypoints.openai.api_server --model Qwen/Qwen3-VL-8B-Instruct --host 0.0.0.0 --port 8002 --gpu-memory-utilization 0.9 --tensor-parallel-size 1 --max-model-len 8192 > ~/vllm.log 2>&1 & tail -f ~/vllm.log

# comment to stay connected to cluster in the background.
ssh -fN context3

