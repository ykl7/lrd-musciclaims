{
  "paper_id": "PMC9535040",
  "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9535040/",
  "figures": {
    "figure_1": {
      "figure_number": "Figure 1",
      "title": "Fig. 1.",
      "caption": "From eye orientation to higher-order eye-tracking measures. This is a crude division of the process from eye orientation to higher-order eye-tracking measures. There may be cases where a more fine-grained division is applicable",
      "possible_urls": [
        [
          "original_src",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9111/9918593/56610033d759/13428_2021_1762_Fig1_HTML.jpg"
        ],
        [
          "large_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9111/9918593/56610033d759/13428_2021_1762_Fig1_HTML.jpg?maxwidth=2000"
        ],
        [
          "original_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9111/9918593/56610033d759/13428_2021_1762_Fig1_HTML.jpg?size=original"
        ],
        [
          "xlarge_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9111/9918593/56610033d759/13428_2021_1762_Fig1_HTML.jpg?maxwidth=4000"
        ]
      ],
      "figure_id": "Fig1",
      "is_table": false,
      "working_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9111/9918593/56610033d759/13428_2021_1762_Fig1_HTML.jpg",
      "download_success": true,
      "local_image_path": "./data/PMC9535040/images/figure_1.jpg",
      "final_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9111/9918593/56610033d759/13428_2021_1762_Fig1_HTML.jpg"
    },
    "figure_2": {
      "figure_number": "Figure 2",
      "title": "Fig. 2.",
      "caption": "Characteristics of eye-tracking data quality. A Horizontal gaze position (in Fick, 1854, coordinates, see Haslwanter (1995)) of the right eye as a function of time. The gaze position was recorded from an adult participant with an EyeLink 1000 by Hooge et al., (2015). Call-outs indicate the relatively precise gaze-position signal (compared with panel B). B Horizontal gaze position in Fick coordinates of the right eye as a function of time. The gaze position was recorded from an infant participant with the Tobii TX300 by Hessels et al., (2016). Call-outs indicate the relatively imprecise gaze-position signal (compared with panel A), short gaps in the gaze-position signal (data loss), and an extreme gaze position reported by the eye tracker. The extreme gaze position is interesting because it can be considered an aspect of eye-tracking data quality not captured in the measures accuracy, precision, or data loss. C, D Gaze position signals (black dots) in a 2D representation, i.e. as if on a screen. Gaze position signals were recorded from adult participants by Hooge et al., (2019). Gaze position samples with high velocity were removed such that saccades are not visible. Orange markers represent validation targets. They are positioned to illustrate good/poor accuracy and do not correspond to the location of the actual validation targets in the experiment by Hooge et al., (2019). Call-outs indicate validation targets with corresponding precise and accurate, precise and inaccurate, imprecise and accurate, and imprecise and inaccurate gaze position signals, respectively. Note that the qualifications ‘precise’, ‘imprecise’, ‘accurate’, and ‘inaccurate’ are relative here and are often quantified",
      "possible_urls": [
        [
          "original_src",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9111/9918593/c9cc3e4aa5e0/13428_2021_1762_Fig2_HTML.jpg"
        ],
        [
          "large_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9111/9918593/c9cc3e4aa5e0/13428_2021_1762_Fig2_HTML.jpg?maxwidth=2000"
        ],
        [
          "original_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9111/9918593/c9cc3e4aa5e0/13428_2021_1762_Fig2_HTML.jpg?size=original"
        ],
        [
          "xlarge_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9111/9918593/c9cc3e4aa5e0/13428_2021_1762_Fig2_HTML.jpg?maxwidth=4000"
        ]
      ],
      "figure_id": "Fig2",
      "is_table": false,
      "working_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9111/9918593/c9cc3e4aa5e0/13428_2021_1762_Fig2_HTML.jpg",
      "download_success": true,
      "local_image_path": "./data/PMC9535040/images/figure_2.jpg",
      "final_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9111/9918593/c9cc3e4aa5e0/13428_2021_1762_Fig2_HTML.jpg"
    },
    "figure_3": {
      "figure_number": "Figure 3",
      "title": "Fig. 3.",
      "caption": "Example of a head-boxed eye-tracking setup. The setup consists of a participant, eye tracker (camera and IR illuminator) and a computer screen. The geometry of this setup can be described by the relative orientations and distances of the monitor, camera and IR illuminator, and participant. Some eye trackers have a fixed relation with the computer screen (e.g. Tobii Pro Spectrum), while others do not and allow for more adjustments (e.g. SR Research EyeLink 1000). Note that the eye-tracker distance and screen distance are not identical. Screen height and width refer to both the physical and the pixel measures",
      "possible_urls": [
        [
          "original_src",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9111/9918593/1d7b8a4a7c4a/13428_2021_1762_Fig3_HTML.jpg"
        ],
        [
          "large_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9111/9918593/1d7b8a4a7c4a/13428_2021_1762_Fig3_HTML.jpg?maxwidth=2000"
        ],
        [
          "original_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9111/9918593/1d7b8a4a7c4a/13428_2021_1762_Fig3_HTML.jpg?size=original"
        ],
        [
          "xlarge_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9111/9918593/1d7b8a4a7c4a/13428_2021_1762_Fig3_HTML.jpg?maxwidth=4000"
        ]
      ],
      "figure_id": "Fig3",
      "is_table": false,
      "working_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9111/9918593/1d7b8a4a7c4a/13428_2021_1762_Fig3_HTML.jpg",
      "download_success": true,
      "local_image_path": "./data/PMC9535040/images/figure_3.jpg",
      "final_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9111/9918593/1d7b8a4a7c4a/13428_2021_1762_Fig3_HTML.jpg"
    }
  },
  "claims": [
    {
      "sentence": "Also, researchers may be interested in how the quality of eye-tracking data affects eye-movement measures when fed through a particular aspect of the eye-tracking data analysis pipeline (Fig. 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "Figure 1 furthermore depicts a general flow from eye-tracking recording to eye-movement measure.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This final section is written from the point of view that any aspect of a study that matters to the outcome of a study should be reported.Measuring data quality of eye-tracker signals\nEye-tracking data quality is often characterised by three measures: accuracy, precision, and data loss (see Fig. 2).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "We can expect that gaze position errors induced by the pupil-size artefact will inevitably propagate to many AOI- and other higher-order measures.Environmental vibrations and ambient noise\nSources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "A picture or schematic can be useful in providing this information, as done in Choe et al., (2016, Figure 1), Hessels & Hooge (2019, Figure 2), Valtakari et al., (2021, Figure 1), and our Fig. 3.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.Physical properties of the eye region\nDifferences in eye physiology refers to eye colour, lash direction, ocular dominance, baseline pupil size and more.",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        },
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel A",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel B",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Also, researchers may be interested in how the quality of eye-tracking data affects eye-movement measures when fed through a particular aspect of the eye-tracking data analysis pipeline (Fig. 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "Figure 1 furthermore depicts a general flow from eye-tracking recording to eye-movement measure.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This final section is written from the point of view that any aspect of a study that matters to the outcome of a study should be reported.Measuring data quality of eye-tracker signals\nEye-tracking data quality is often characterised by three measures: accuracy, precision, and data loss (see Fig. 2).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "We can expect that gaze position errors induced by the pupil-size artefact will inevitably propagate to many AOI- and other higher-order measures.Environmental vibrations and ambient noise\nSources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "A picture or schematic can be useful in providing this information, as done in Choe et al., (2016, Figure 1), Hessels & Hooge (2019, Figure 2), Valtakari et al., (2021, Figure 1), and our Fig. 3.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.Physical properties of the eye region\nDifferences in eye physiology refers to eye colour, lash direction, ocular dominance, baseline pupil size and more.",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        },
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel A",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel B",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Also, researchers may be interested in how the quality of eye-tracking data affects eye-movement measures when fed through a particular aspect of the eye-tracking data analysis pipeline (Fig. 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "Figure 1 furthermore depicts a general flow from eye-tracking recording to eye-movement measure.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This final section is written from the point of view that any aspect of a study that matters to the outcome of a study should be reported.Measuring data quality of eye-tracker signals\nEye-tracking data quality is often characterised by three measures: accuracy, precision, and data loss (see Fig. 2).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "We can expect that gaze position errors induced by the pupil-size artefact will inevitably propagate to many AOI- and other higher-order measures.Environmental vibrations and ambient noise\nSources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "A picture or schematic can be useful in providing this information, as done in Choe et al., (2016, Figure 1), Hessels & Hooge (2019, Figure 2), Valtakari et al., (2021, Figure 1), and our Fig. 3.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.Physical properties of the eye region\nDifferences in eye physiology refers to eye colour, lash direction, ocular dominance, baseline pupil size and more.",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        },
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel A",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel B",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Also, researchers may be interested in how the quality of eye-tracking data affects eye-movement measures when fed through a particular aspect of the eye-tracking data analysis pipeline (Fig. 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "Figure 1 furthermore depicts a general flow from eye-tracking recording to eye-movement measure.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This final section is written from the point of view that any aspect of a study that matters to the outcome of a study should be reported.Measuring data quality of eye-tracker signals\nEye-tracking data quality is often characterised by three measures: accuracy, precision, and data loss (see Fig. 2).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "We can expect that gaze position errors induced by the pupil-size artefact will inevitably propagate to many AOI- and other higher-order measures.Environmental vibrations and ambient noise\nSources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "A picture or schematic can be useful in providing this information, as done in Choe et al., (2016, Figure 1), Hessels & Hooge (2019, Figure 2), Valtakari et al., (2021, Figure 1), and our Fig. 3.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.Physical properties of the eye region\nDifferences in eye physiology refers to eye colour, lash direction, ocular dominance, baseline pupil size and more.",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        },
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel A",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel B",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Also, researchers may be interested in how the quality of eye-tracking data affects eye-movement measures when fed through a particular aspect of the eye-tracking data analysis pipeline (Fig. 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "Figure 1 furthermore depicts a general flow from eye-tracking recording to eye-movement measure.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This final section is written from the point of view that any aspect of a study that matters to the outcome of a study should be reported.Measuring data quality of eye-tracker signals\nEye-tracking data quality is often characterised by three measures: accuracy, precision, and data loss (see Fig. 2).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "We can expect that gaze position errors induced by the pupil-size artefact will inevitably propagate to many AOI- and other higher-order measures.Environmental vibrations and ambient noise\nSources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "A picture or schematic can be useful in providing this information, as done in Choe et al., (2016, Figure 1), Hessels & Hooge (2019, Figure 2), Valtakari et al., (2021, Figure 1), and our Fig. 3.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.Physical properties of the eye region\nDifferences in eye physiology refers to eye colour, lash direction, ocular dominance, baseline pupil size and more.",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        },
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel A",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel B",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Also, researchers may be interested in how the quality of eye-tracking data affects eye-movement measures when fed through a particular aspect of the eye-tracking data analysis pipeline (Fig. 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "Figure 1 furthermore depicts a general flow from eye-tracking recording to eye-movement measure.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This final section is written from the point of view that any aspect of a study that matters to the outcome of a study should be reported.Measuring data quality of eye-tracker signals\nEye-tracking data quality is often characterised by three measures: accuracy, precision, and data loss (see Fig. 2).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "We can expect that gaze position errors induced by the pupil-size artefact will inevitably propagate to many AOI- and other higher-order measures.Environmental vibrations and ambient noise\nSources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "A picture or schematic can be useful in providing this information, as done in Choe et al., (2016, Figure 1), Hessels & Hooge (2019, Figure 2), Valtakari et al., (2021, Figure 1), and our Fig. 3.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.Physical properties of the eye region\nDifferences in eye physiology refers to eye colour, lash direction, ocular dominance, baseline pupil size and more.",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        },
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel A",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel B",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Also, researchers may be interested in how the quality of eye-tracking data affects eye-movement measures when fed through a particular aspect of the eye-tracking data analysis pipeline (Fig. 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "Figure 1 furthermore depicts a general flow from eye-tracking recording to eye-movement measure.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This final section is written from the point of view that any aspect of a study that matters to the outcome of a study should be reported.Measuring data quality of eye-tracker signals\nEye-tracking data quality is often characterised by three measures: accuracy, precision, and data loss (see Fig. 2).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "We can expect that gaze position errors induced by the pupil-size artefact will inevitably propagate to many AOI- and other higher-order measures.Environmental vibrations and ambient noise\nSources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "A picture or schematic can be useful in providing this information, as done in Choe et al., (2016, Figure 1), Hessels & Hooge (2019, Figure 2), Valtakari et al., (2021, Figure 1), and our Fig. 3.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.Physical properties of the eye region\nDifferences in eye physiology refers to eye colour, lash direction, ocular dominance, baseline pupil size and more.",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        },
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel A",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel B",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Also, researchers may be interested in how the quality of eye-tracking data affects eye-movement measures when fed through a particular aspect of the eye-tracking data analysis pipeline (Fig. 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "Figure 1 furthermore depicts a general flow from eye-tracking recording to eye-movement measure.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This final section is written from the point of view that any aspect of a study that matters to the outcome of a study should be reported.Measuring data quality of eye-tracker signals\nEye-tracking data quality is often characterised by three measures: accuracy, precision, and data loss (see Fig. 2).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "We can expect that gaze position errors induced by the pupil-size artefact will inevitably propagate to many AOI- and other higher-order measures.Environmental vibrations and ambient noise\nSources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "A picture or schematic can be useful in providing this information, as done in Choe et al., (2016, Figure 1), Hessels & Hooge (2019, Figure 2), Valtakari et al., (2021, Figure 1), and our Fig. 3.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.Physical properties of the eye region\nDifferences in eye physiology refers to eye colour, lash direction, ocular dominance, baseline pupil size and more.",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        },
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel A",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel B",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Also, researchers may be interested in how the quality of eye-tracking data affects eye-movement measures when fed through a particular aspect of the eye-tracking data analysis pipeline (Fig. 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "Also, researchers may be interested in how the quality of eye-tracking data affects eye-movement measures when fed through a particular aspect of the eye-tracking data analysis pipeline (Fig. 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "Figure 1 furthermore depicts a general flow from eye-tracking recording to eye-movement measure.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "Figure 1 furthermore depicts a general flow from eye-tracking recording to eye-movement measure.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "Measuring data quality of eye-tracker signals\nEye-tracking data quality is often characterised by three measures: accuracy, precision, and data loss (see Fig. 2).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Eye-tracking data quality is often characterised by three measures: accuracy, precision, and data loss (see Fig. 2).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "We can expect that gaze position errors induced by the pupil-size artefact will inevitably propagate to many AOI- and other higher-order measures.Environmental vibrations and ambient noise\nSources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "A picture or schematic can be useful in providing this information, as done in Choe et al., (2016, Figure 1), Hessels & Hooge (2019, Figure 2), Valtakari et al., (2021, Figure 1), and our Fig. 3.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.Physical properties of the eye region\nDifferences in eye physiology refers to eye colour, lash direction, ocular dominance, baseline pupil size and more.",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        },
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel A",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel B",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "We can expect that gaze position errors induced by the pupil-size artefact will inevitably propagate to many AOI- and other higher-order measures.Environmental vibrations and ambient noise\nSources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Environmental vibrations and ambient noise\nSources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Sources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "A picture or schematic can be useful in providing this information, as done in Choe et al., (2016, Figure 1), Hessels & Hooge (2019, Figure 2), Valtakari et al., (2021, Figure 1), and our Fig. 3.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "A picture or schematic can be useful in providing this information, as done in Choe et al., (2016, Figure 1), Hessels & Hooge (2019, Figure 2), Valtakari et al., (2021, Figure 1), and our Fig. 3.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.Physical properties of the eye region\nDifferences in eye physiology refers to eye colour, lash direction, ocular dominance, baseline pupil size and more.",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        },
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        },
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        },
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel A",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel B",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel A",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel B",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel A",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "Panel B",
          "figure_key": "figure_2"
        }
      ]
    }
  ],
  "extraction_stats": {
    "figures_count": 3,
    "claims_count": 185,
    "images_downloaded": 3,
    "tables_filtered": 83
  }
}