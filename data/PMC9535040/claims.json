[
  {
    "sentence": "Also, researchers may be interested in how the quality of eye-tracking data affects eye-movement measures when fed through a particular aspect of the eye-tracking data analysis pipeline (Fig. 1).",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "Figure 1 furthermore depicts a general flow from eye-tracking recording to eye-movement measure.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "This final section is written from the point of view that any aspect of a study that matters to the outcome of a study should be reported.Measuring data quality of eye-tracker signals\nEye-tracking data quality is often characterised by three measures: accuracy, precision, and data loss (see Fig. 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "We can expect that gaze position errors induced by the pupil-size artefact will inevitably propagate to many AOI- and other higher-order measures.Environmental vibrations and ambient noise\nSources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "A picture or schematic can be useful in providing this information, as done in Choe et al., (2016, Figure 1), Hessels & Hooge (2019, Figure 2), Valtakari et al., (2021, Figure 1), and our Fig. 3.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.Physical properties of the eye region\nDifferences in eye physiology refers to eye colour, lash direction, ocular dominance, baseline pupil size and more.",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
    "figure_references": [
      {
        "figure_number": "Figure 11",
        "panel": "",
        "figure_key": "figure_11"
      }
    ]
  },
  {
    "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      },
      {
        "figure_number": "Figure 9",
        "panel": "",
        "figure_key": "figure_9"
      }
    ]
  },
  {
    "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel A",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel B",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Also, researchers may be interested in how the quality of eye-tracking data affects eye-movement measures when fed through a particular aspect of the eye-tracking data analysis pipeline (Fig. 1).",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "Figure 1 furthermore depicts a general flow from eye-tracking recording to eye-movement measure.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "This final section is written from the point of view that any aspect of a study that matters to the outcome of a study should be reported.Measuring data quality of eye-tracker signals\nEye-tracking data quality is often characterised by three measures: accuracy, precision, and data loss (see Fig. 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "We can expect that gaze position errors induced by the pupil-size artefact will inevitably propagate to many AOI- and other higher-order measures.Environmental vibrations and ambient noise\nSources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "A picture or schematic can be useful in providing this information, as done in Choe et al., (2016, Figure 1), Hessels & Hooge (2019, Figure 2), Valtakari et al., (2021, Figure 1), and our Fig. 3.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.Physical properties of the eye region\nDifferences in eye physiology refers to eye colour, lash direction, ocular dominance, baseline pupil size and more.",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
    "figure_references": [
      {
        "figure_number": "Figure 11",
        "panel": "",
        "figure_key": "figure_11"
      }
    ]
  },
  {
    "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      },
      {
        "figure_number": "Figure 9",
        "panel": "",
        "figure_key": "figure_9"
      }
    ]
  },
  {
    "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel A",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel B",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Also, researchers may be interested in how the quality of eye-tracking data affects eye-movement measures when fed through a particular aspect of the eye-tracking data analysis pipeline (Fig. 1).",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "Figure 1 furthermore depicts a general flow from eye-tracking recording to eye-movement measure.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "This final section is written from the point of view that any aspect of a study that matters to the outcome of a study should be reported.Measuring data quality of eye-tracker signals\nEye-tracking data quality is often characterised by three measures: accuracy, precision, and data loss (see Fig. 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "We can expect that gaze position errors induced by the pupil-size artefact will inevitably propagate to many AOI- and other higher-order measures.Environmental vibrations and ambient noise\nSources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "A picture or schematic can be useful in providing this information, as done in Choe et al., (2016, Figure 1), Hessels & Hooge (2019, Figure 2), Valtakari et al., (2021, Figure 1), and our Fig. 3.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.Physical properties of the eye region\nDifferences in eye physiology refers to eye colour, lash direction, ocular dominance, baseline pupil size and more.",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
    "figure_references": [
      {
        "figure_number": "Figure 11",
        "panel": "",
        "figure_key": "figure_11"
      }
    ]
  },
  {
    "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      },
      {
        "figure_number": "Figure 9",
        "panel": "",
        "figure_key": "figure_9"
      }
    ]
  },
  {
    "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel A",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel B",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Also, researchers may be interested in how the quality of eye-tracking data affects eye-movement measures when fed through a particular aspect of the eye-tracking data analysis pipeline (Fig. 1).",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "Figure 1 furthermore depicts a general flow from eye-tracking recording to eye-movement measure.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "This final section is written from the point of view that any aspect of a study that matters to the outcome of a study should be reported.Measuring data quality of eye-tracker signals\nEye-tracking data quality is often characterised by three measures: accuracy, precision, and data loss (see Fig. 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "We can expect that gaze position errors induced by the pupil-size artefact will inevitably propagate to many AOI- and other higher-order measures.Environmental vibrations and ambient noise\nSources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "A picture or schematic can be useful in providing this information, as done in Choe et al., (2016, Figure 1), Hessels & Hooge (2019, Figure 2), Valtakari et al., (2021, Figure 1), and our Fig. 3.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.Physical properties of the eye region\nDifferences in eye physiology refers to eye colour, lash direction, ocular dominance, baseline pupil size and more.",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
    "figure_references": [
      {
        "figure_number": "Figure 11",
        "panel": "",
        "figure_key": "figure_11"
      }
    ]
  },
  {
    "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      },
      {
        "figure_number": "Figure 9",
        "panel": "",
        "figure_key": "figure_9"
      }
    ]
  },
  {
    "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel A",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel B",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Also, researchers may be interested in how the quality of eye-tracking data affects eye-movement measures when fed through a particular aspect of the eye-tracking data analysis pipeline (Fig. 1).",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "Figure 1 furthermore depicts a general flow from eye-tracking recording to eye-movement measure.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "This final section is written from the point of view that any aspect of a study that matters to the outcome of a study should be reported.Measuring data quality of eye-tracker signals\nEye-tracking data quality is often characterised by three measures: accuracy, precision, and data loss (see Fig. 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "We can expect that gaze position errors induced by the pupil-size artefact will inevitably propagate to many AOI- and other higher-order measures.Environmental vibrations and ambient noise\nSources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "A picture or schematic can be useful in providing this information, as done in Choe et al., (2016, Figure 1), Hessels & Hooge (2019, Figure 2), Valtakari et al., (2021, Figure 1), and our Fig. 3.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.Physical properties of the eye region\nDifferences in eye physiology refers to eye colour, lash direction, ocular dominance, baseline pupil size and more.",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
    "figure_references": [
      {
        "figure_number": "Figure 11",
        "panel": "",
        "figure_key": "figure_11"
      }
    ]
  },
  {
    "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      },
      {
        "figure_number": "Figure 9",
        "panel": "",
        "figure_key": "figure_9"
      }
    ]
  },
  {
    "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel A",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel B",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Also, researchers may be interested in how the quality of eye-tracking data affects eye-movement measures when fed through a particular aspect of the eye-tracking data analysis pipeline (Fig. 1).",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "Figure 1 furthermore depicts a general flow from eye-tracking recording to eye-movement measure.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "This final section is written from the point of view that any aspect of a study that matters to the outcome of a study should be reported.Measuring data quality of eye-tracker signals\nEye-tracking data quality is often characterised by three measures: accuracy, precision, and data loss (see Fig. 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "We can expect that gaze position errors induced by the pupil-size artefact will inevitably propagate to many AOI- and other higher-order measures.Environmental vibrations and ambient noise\nSources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "A picture or schematic can be useful in providing this information, as done in Choe et al., (2016, Figure 1), Hessels & Hooge (2019, Figure 2), Valtakari et al., (2021, Figure 1), and our Fig. 3.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.Physical properties of the eye region\nDifferences in eye physiology refers to eye colour, lash direction, ocular dominance, baseline pupil size and more.",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
    "figure_references": [
      {
        "figure_number": "Figure 11",
        "panel": "",
        "figure_key": "figure_11"
      }
    ]
  },
  {
    "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      },
      {
        "figure_number": "Figure 9",
        "panel": "",
        "figure_key": "figure_9"
      }
    ]
  },
  {
    "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel A",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel B",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Also, researchers may be interested in how the quality of eye-tracking data affects eye-movement measures when fed through a particular aspect of the eye-tracking data analysis pipeline (Fig. 1).",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "Figure 1 furthermore depicts a general flow from eye-tracking recording to eye-movement measure.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "This final section is written from the point of view that any aspect of a study that matters to the outcome of a study should be reported.Measuring data quality of eye-tracker signals\nEye-tracking data quality is often characterised by three measures: accuracy, precision, and data loss (see Fig. 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "We can expect that gaze position errors induced by the pupil-size artefact will inevitably propagate to many AOI- and other higher-order measures.Environmental vibrations and ambient noise\nSources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "A picture or schematic can be useful in providing this information, as done in Choe et al., (2016, Figure 1), Hessels & Hooge (2019, Figure 2), Valtakari et al., (2021, Figure 1), and our Fig. 3.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.Physical properties of the eye region\nDifferences in eye physiology refers to eye colour, lash direction, ocular dominance, baseline pupil size and more.",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
    "figure_references": [
      {
        "figure_number": "Figure 11",
        "panel": "",
        "figure_key": "figure_11"
      }
    ]
  },
  {
    "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      },
      {
        "figure_number": "Figure 9",
        "panel": "",
        "figure_key": "figure_9"
      }
    ]
  },
  {
    "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel A",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel B",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Also, researchers may be interested in how the quality of eye-tracking data affects eye-movement measures when fed through a particular aspect of the eye-tracking data analysis pipeline (Fig. 1).",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "Figure 1 furthermore depicts a general flow from eye-tracking recording to eye-movement measure.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "This final section is written from the point of view that any aspect of a study that matters to the outcome of a study should be reported.Measuring data quality of eye-tracker signals\nEye-tracking data quality is often characterised by three measures: accuracy, precision, and data loss (see Fig. 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "We can expect that gaze position errors induced by the pupil-size artefact will inevitably propagate to many AOI- and other higher-order measures.Environmental vibrations and ambient noise\nSources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "A picture or schematic can be useful in providing this information, as done in Choe et al., (2016, Figure 1), Hessels & Hooge (2019, Figure 2), Valtakari et al., (2021, Figure 1), and our Fig. 3.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.Physical properties of the eye region\nDifferences in eye physiology refers to eye colour, lash direction, ocular dominance, baseline pupil size and more.",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
    "figure_references": [
      {
        "figure_number": "Figure 11",
        "panel": "",
        "figure_key": "figure_11"
      }
    ]
  },
  {
    "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      },
      {
        "figure_number": "Figure 9",
        "panel": "",
        "figure_key": "figure_9"
      }
    ]
  },
  {
    "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel A",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel B",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Also, researchers may be interested in how the quality of eye-tracking data affects eye-movement measures when fed through a particular aspect of the eye-tracking data analysis pipeline (Fig. 1).",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "Also, researchers may be interested in how the quality of eye-tracking data affects eye-movement measures when fed through a particular aspect of the eye-tracking data analysis pipeline (Fig. 1).",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "Figure 1 furthermore depicts a general flow from eye-tracking recording to eye-movement measure.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "Figure 1 furthermore depicts a general flow from eye-tracking recording to eye-movement measure.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "Measuring data quality of eye-tracker signals\nEye-tracking data quality is often characterised by three measures: accuracy, precision, and data loss (see Fig. 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Eye-tracking data quality is often characterised by three measures: accuracy, precision, and data loss (see Fig. 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "We can expect that gaze position errors induced by the pupil-size artefact will inevitably propagate to many AOI- and other higher-order measures.Environmental vibrations and ambient noise\nSources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "A picture or schematic can be useful in providing this information, as done in Choe et al., (2016, Figure 1), Hessels & Hooge (2019, Figure 2), Valtakari et al., (2021, Figure 1), and our Fig. 3.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.Physical properties of the eye region\nDifferences in eye physiology refers to eye colour, lash direction, ocular dominance, baseline pupil size and more.",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
    "figure_references": [
      {
        "figure_number": "Figure 11",
        "panel": "",
        "figure_key": "figure_11"
      }
    ]
  },
  {
    "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      },
      {
        "figure_number": "Figure 9",
        "panel": "",
        "figure_key": "figure_9"
      }
    ]
  },
  {
    "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel A",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel B",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Blue irises tend to result in poorer precision (in dark-pupil eye trackers), which is due to poor contrast between (a dark) pupil and iris in the infra-red light of video-based eye trackers (Section “Participants”, and Figure 4.13 in Holmqvist & Andersson, 2017).",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Small movements will drown in the noise of EOG data (compare Fig. 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "We can expect that gaze position errors induced by the pupil-size artefact will inevitably propagate to many AOI- and other higher-order measures.Environmental vibrations and ambient noise\nSources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "Environmental vibrations and ambient noise\nSources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "Sources of vibration in the recording environment contribute to increased variation in the gaze signal, as exemplified by Figure 6.24 in Holmqvist and Andersson (2017), showing how transients in the signal appear when a person walks in a room where an artificial eye is being measured with a tower eye tracker.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "A picture or schematic can be useful in providing this information, as done in Choe et al., (2016, Figure 1), Hessels & Hooge (2019, Figure 2), Valtakari et al., (2021, Figure 1), and our Fig. 3.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "A picture or schematic can be useful in providing this information, as done in Choe et al., (2016, Figure 1), Hessels & Hooge (2019, Figure 2), Valtakari et al., (2021, Figure 1), and our Fig. 3.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      },
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      },
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "While the original P–CR method may handle small movements of the head, at the size of a few millimetres up to a centimetre, recent remote video-based eye trackers are designed to allow for free head movements in a much larger space (the headbox, see Fig. 3), tens of centimetres or more across.",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "However, some eye trackers change sampling frequency altogether when the eye is lost in the recording window of the camera sensor and the eye tracker goes into full-sensor search mode (Hessels et al.,, 2015, Figure 3).",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.Physical properties of the eye region\nDifferences in eye physiology refers to eye colour, lash direction, ocular dominance, baseline pupil size and more.",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "Mascara is black in both infrared and visible light, and Holmqvist and Andersson (2017, Figure 5.5) show eye images from actual recordings that depict how the dark mascara may interact with the pupil center calculation.",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "The advantage of dark iris pigmentation over blue eyes has been hypothesised to result from poor contrast between pupil and iris when the eye image is recorded in infrared light: A blue iris is dark, while a brown iris is bright (Holmqvist and Andersson, 2017, Figure 4.13), providing a clearer contrast between iris and the dark pupil, which the image processing algorithms can make better use of.",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Nyström et al., (2013) report a 0.2∘ drift during a 15-min reading task with the SMI HiSpeed 1250, and Choe et al., (2016, Figure 2) show drift due to the pupil-size artefact.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
    "figure_references": [
      {
        "figure_number": "Figure 11",
        "panel": "",
        "figure_key": "figure_11"
      }
    ]
  },
  {
    "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      },
      {
        "figure_number": "Figure 9",
        "panel": "",
        "figure_key": "figure_9"
      }
    ]
  },
  {
    "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
    "figure_references": [
      {
        "figure_number": "Figure 11",
        "panel": "",
        "figure_key": "figure_11"
      }
    ]
  },
  {
    "sentence": "However, the alternating samples are offset in the resulting data, yielding a zigzag pattern that is very common in 100Hz data from Tobii Glasses but does not happen in 50Hz data (see Figure 11 in Niehorster et al.,, 2020b).",
    "figure_references": [
      {
        "figure_number": "Figure 11",
        "panel": "",
        "figure_key": "figure_11"
      }
    ]
  },
  {
    "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      },
      {
        "figure_number": "Figure 9",
        "panel": "",
        "figure_key": "figure_9"
      }
    ]
  },
  {
    "sentence": "167), Hessels et al., (2015, Figure 6) reported less than 3% data loss for the TX300 for upright head orientations, and Hessels & Hooge (2019, Figure 9) reported less than 10% data loss for 9 year old children measured with the TX300.",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      },
      {
        "figure_number": "Figure 9",
        "panel": "",
        "figure_key": "figure_9"
      }
    ]
  },
  {
    "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel A",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel B",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel A",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel B",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "For instance, Fig. 2A shows how the large saccades are often followed by small saccades which are clearly seen and reasonably easy to detect by algorithms.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel A",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "In Fig. 2B, the big saccades are visible, but the small saccades, if they were made during the recording, have left a trace that is harder to distinguish from noise, for human data inspectors and algorithms alike.",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel B",
        "figure_key": "figure_2"
      }
    ]
  }
]