paper_id,claim,figure_id,title,caption,local_image_path,url
PMC11382209,"Explainability methods can be categorised into the following four major categories illustrated in Fig. 1, each contributing to a deeper understanding and greater transparency of the algorithmic process.",PMC11382209_figure_1,,,./data/PMC11382209/images/figure_1.jpg,https://cdn.ncbi.nlm.nih.gov/pmc/blobs/25e5/11382209/ce7a46549d2c/gr001.jpg
PMC11382209,"The search string utilised for querying these databases based on metadata attributes, including title, abstract, and keywords, is summarised in Fig. 2.",PMC11382209_figure_2,Fig. 1.,Proposed framework for categorizing XAI methods based on taxonomies in extant literature.,./data/PMC11382209/images/figure_2.jpg,https://cdn.ncbi.nlm.nih.gov/pmc/blobs/25e5/11382209/b93372267b3c/gr002.jpg
PMC11382209,"A set of inclusion and exclusion criteria Table 1 was established to ensure a systematic and replicable selection, as presented in the flow diagram (Fig. 3) of our review, which shows the number of studies identified, screened and included in this review.",PMC11382209_figure_3,Fig. 2.,Search string.,./data/PMC11382209/images/figure_3.jpg,https://cdn.ncbi.nlm.nih.gov/pmc/blobs/25e5/11382209/7e6f2e126bf9/gr003.jpg
PMC11382209,"Preliminary analysis
Fig. 4 (extracted from Table 2) offers an insightful glimpse of the changing landscape of published research work in the realm of XAI in medical imaging between 2015 to 2023,2 breaking down the output into conference, journal and survey papers.",PMC11382209_figure_4,Fig. 3.,"Flow diagram of our review, it shows the number of studies identified, screened and included in this review.",./data/PMC11382209/images/figure_4.jpg,https://cdn.ncbi.nlm.nih.gov/pmc/blobs/25e5/11382209/6d36ead32d20/gr004.jpg
PMC11382209,"Additionally, 44 out of 49 papers are cited by researchers in their technical works, indicating a strong interest in utilising XAI for medical images analysis and healthcare applications (Fig. 5).",PMC11382209_figure_5,Fig. 4.,No. of publications per year.,./data/PMC11382209/images/figure_5.jpg,https://cdn.ncbi.nlm.nih.gov/pmc/blobs/25e5/11382209/895c88679fc1/gr005.jpg
PMC11382209,"Open in a new tab
No. of publications per year.Fig. 5.",PMC11382209_figure_5,Fig. 4.,No. of publications per year.,./data/PMC11382209/images/figure_5.jpg,https://cdn.ncbi.nlm.nih.gov/pmc/blobs/25e5/11382209/895c88679fc1/gr005.jpg
PMC11382209,"SHAP for medical images
This section summarises the work that used SHAP as the XAI method for medical image analysis (Fig. 6).",PMC11382209_figure_6,Fig. 5.,"RISE, Grad-CAM, OA and LIME explanations by [65], display human annotations and explanations generated by mentioned methods for a COVID-19 CT image. Each explanation technique highlights salient regions responsible for the prediction. Human annotations highlight different salient regions. In the generated explanations, red regions indicate areas contributing to the prediction when using RISE, Grad-CAM, and OA. LIME differentiates pixels supporting the prediction in green and those negating the prediction in red.",./data/PMC11382209/images/figure_6.jpg,https://cdn.ncbi.nlm.nih.gov/pmc/blobs/25e5/11382209/69f3990be3d7/gr006.jpg
PMC11382209,The authors explained their model outcomes using the CAM (Fig. 7).,PMC11382209_figure_7,Fig. 6.,"SHAP explanations by [72], illustrated feature importance using SHAP values. Each row in the figure represents a different feature, while each point corresponds to a sample. The colour gradient indicates the value of the feature: redder points signify larger values, while bluer points represent smaller values. In the context of mortality prediction, treated as a binary classification problem where 1 indicates death, the figure shows several red points on the right side of the SHAP values for features like CRP and LDH, suggesting that higher values of these features are associated with an increased risk of mortality. Conversely, for the lymphocyte feature, blue points are concentrated on the right, indicating that lower lymphocyte levels are linked to higher mortality. Overall, the figure demonstrates that elevated levels of LDH and CRP, along with reduced lymphocyte levels, are associated with a higher likelihood of death.",./data/PMC11382209/images/figure_7.jpg,https://cdn.ncbi.nlm.nih.gov/pmc/blobs/25e5/11382209/c00261f86308/gr007.jpg
PMC11382209,"Additionally, LRP occasionally overemphasises regions that lack clinical relevance, which mislead healthcare professionals (Fig. 8).",PMC11382209_figure_8,Fig. 7.,"CAM visualization utilizing the Saliency map by [82], illustrates results for four examples, showing annotated input images, ROI patches, saliency maps for benign and malignant classes, and ROI patches with attention scores. The top example features a circumscribed oval mass in the left upper breast middle depth, diagnosed as a benign fibroadenoma via ultrasound biopsy. The second example displays an irregular mass in the right lateral breast posterior depth, diagnosed as invasive ductal carcinoma via ultrasound biopsy. The third example's saliency maps identify benign findings: a circumscribed oval mass confirmed as a benign fibroadenoma, a smaller oval mass recommended for follow-up, and an asymmetry that is stable and benign. The bottom example shows segmental coarse heterogeneous calcifications in the right central breast middle depth, diagnosed as high-grade ductal carcinoma in situ via stereotactic biopsy.",./data/PMC11382209/images/figure_8.jpg,https://cdn.ncbi.nlm.nih.gov/pmc/blobs/25e5/11382209/9ae6adbeb25e/gr008.jpg
PMC11382209,"Fig. 4 (extracted from Table 2) offers an insightful glimpse of the changing landscape of published research work in the realm of XAI in medical imaging between 2015 to 2023,2 breaking down the output into conference, journal and survey papers.",PMC11382209_figure_4,Fig. 3.,"Flow diagram of our review, it shows the number of studies identified, screened and included in this review.",./data/PMC11382209/images/figure_4.jpg,https://cdn.ncbi.nlm.nih.gov/pmc/blobs/25e5/11382209/6d36ead32d20/gr004.jpg
PMC11382209,This section summarises the work that used SHAP as the XAI method for medical image analysis (Fig. 6).,PMC11382209_figure_6,Fig. 5.,"RISE, Grad-CAM, OA and LIME explanations by [65], display human annotations and explanations generated by mentioned methods for a COVID-19 CT image. Each explanation technique highlights salient regions responsible for the prediction. Human annotations highlight different salient regions. In the generated explanations, red regions indicate areas contributing to the prediction when using RISE, Grad-CAM, and OA. LIME differentiates pixels supporting the prediction in green and those negating the prediction in red.",./data/PMC11382209/images/figure_6.jpg,https://cdn.ncbi.nlm.nih.gov/pmc/blobs/25e5/11382209/69f3990be3d7/gr006.jpg
