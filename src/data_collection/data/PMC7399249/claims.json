[
  {
    "sentence": "For a more detailed overview of how facial information is captured with lighting or viewpoint camera arrays within these databases, see Figure 1.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "For example, the database presented in Figure 2B, experiences a loss of data from the posterior viewpoint of the head, which may impede studies examining VR environments (Bulthoff and Edelman, 1992; Stolz et al., 2019; Lamberti et al., 2020) or multiple viewpoints of a facial stimulus (Bülthoff et al., 2018; Abudarham et al., 2019; Zhan et al., 2019).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel B",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Overall, despite some remaining challenges, 3D and 4D facial capture and reconstruction has demonstrated that the unique facial features belonging to you and me, such as the cheeks, eyes and nose, can simulated on-screen in a highly realistic manner (see Figure 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Similarly, the dynamic video-recorded BU4D-S 4D database produced by Zhang et al. (2013, 2014) is the leading 4D database in citation count (Figure 3).",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      },
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "Search on 13/02/2020, including count of the original published journal article of each database.At first glance, the citation count pictured in Figure 4 appears impressive.",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Thus we examined logarithmic growth across academic fields below (Figure 5).",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      },
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "Search terms: (“allintitle, abstract or keywords”: “3-D face” OR “3D face” OR “three-dimensional face” OR “three-dimensional face” OR “4D”).FIGURE 5.",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "One of the greatest contributions 3D face databases offer is the inclusion of unconstrained head motion within space (for some examples see Figure 6 MPI; Kaulard et al., 2012; BP-4D-S; Zhang et al., 2014).",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "Exemplars of different FACS coded muscle activations, illustrating smiles, frowns and grimaces of deformable facial features are displayed in Figure 7.",
    "figure_references": [
      {
        "figure_number": "Figure 7",
        "panel": "",
        "figure_key": "figure_7"
      }
    ]
  },
  {
    "sentence": "For a more detailed overview of how facial information is captured with lighting or viewpoint camera arrays within these databases, see Figure 1.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "For example, the database presented in Figure 2B, experiences a loss of data from the posterior viewpoint of the head, which may impede studies examining VR environments (Bulthoff and Edelman, 1992; Stolz et al., 2019; Lamberti et al., 2020) or multiple viewpoints of a facial stimulus (Bülthoff et al., 2018; Abudarham et al., 2019; Zhan et al., 2019).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel B",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Overall, despite some remaining challenges, 3D and 4D facial capture and reconstruction has demonstrated that the unique facial features belonging to you and me, such as the cheeks, eyes and nose, can simulated on-screen in a highly realistic manner (see Figure 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Similarly, the dynamic video-recorded BU4D-S 4D database produced by Zhang et al. (2013, 2014) is the leading 4D database in citation count (Figure 3).",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      },
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "Search on 13/02/2020, including count of the original published journal article of each database.At first glance, the citation count pictured in Figure 4 appears impressive.",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Thus we examined logarithmic growth across academic fields below (Figure 5).",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      },
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "Search terms: (“allintitle, abstract or keywords”: “3-D face” OR “3D face” OR “three-dimensional face” OR “three-dimensional face” OR “4D”).FIGURE 5.",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "One of the greatest contributions 3D face databases offer is the inclusion of unconstrained head motion within space (for some examples see Figure 6 MPI; Kaulard et al., 2012; BP-4D-S; Zhang et al., 2014).",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "Exemplars of different FACS coded muscle activations, illustrating smiles, frowns and grimaces of deformable facial features are displayed in Figure 7.",
    "figure_references": [
      {
        "figure_number": "Figure 7",
        "panel": "",
        "figure_key": "figure_7"
      }
    ]
  },
  {
    "sentence": "For a more detailed overview of how facial information is captured with lighting or viewpoint camera arrays within these databases, see Figure 1.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "For example, the database presented in Figure 2B, experiences a loss of data from the posterior viewpoint of the head, which may impede studies examining VR environments (Bulthoff and Edelman, 1992; Stolz et al., 2019; Lamberti et al., 2020) or multiple viewpoints of a facial stimulus (Bülthoff et al., 2018; Abudarham et al., 2019; Zhan et al., 2019).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel B",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Overall, despite some remaining challenges, 3D and 4D facial capture and reconstruction has demonstrated that the unique facial features belonging to you and me, such as the cheeks, eyes and nose, can simulated on-screen in a highly realistic manner (see Figure 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Similarly, the dynamic video-recorded BU4D-S 4D database produced by Zhang et al. (2013, 2014) is the leading 4D database in citation count (Figure 3).",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      },
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "Search on 13/02/2020, including count of the original published journal article of each database.At first glance, the citation count pictured in Figure 4 appears impressive.",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Thus we examined logarithmic growth across academic fields below (Figure 5).",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      },
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "Search terms: (“allintitle, abstract or keywords”: “3-D face” OR “3D face” OR “three-dimensional face” OR “three-dimensional face” OR “4D”).FIGURE 5.",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "One of the greatest contributions 3D face databases offer is the inclusion of unconstrained head motion within space (for some examples see Figure 6 MPI; Kaulard et al., 2012; BP-4D-S; Zhang et al., 2014).",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "Exemplars of different FACS coded muscle activations, illustrating smiles, frowns and grimaces of deformable facial features are displayed in Figure 7.",
    "figure_references": [
      {
        "figure_number": "Figure 7",
        "panel": "",
        "figure_key": "figure_7"
      }
    ]
  },
  {
    "sentence": "For a more detailed overview of how facial information is captured with lighting or viewpoint camera arrays within these databases, see Figure 1.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "For example, the database presented in Figure 2B, experiences a loss of data from the posterior viewpoint of the head, which may impede studies examining VR environments (Bulthoff and Edelman, 1992; Stolz et al., 2019; Lamberti et al., 2020) or multiple viewpoints of a facial stimulus (Bülthoff et al., 2018; Abudarham et al., 2019; Zhan et al., 2019).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel B",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Overall, despite some remaining challenges, 3D and 4D facial capture and reconstruction has demonstrated that the unique facial features belonging to you and me, such as the cheeks, eyes and nose, can simulated on-screen in a highly realistic manner (see Figure 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Similarly, the dynamic video-recorded BU4D-S 4D database produced by Zhang et al. (2013, 2014) is the leading 4D database in citation count (Figure 3).",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      },
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "Search on 13/02/2020, including count of the original published journal article of each database.At first glance, the citation count pictured in Figure 4 appears impressive.",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Thus we examined logarithmic growth across academic fields below (Figure 5).",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      },
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "Search terms: (“allintitle, abstract or keywords”: “3-D face” OR “3D face” OR “three-dimensional face” OR “three-dimensional face” OR “4D”).FIGURE 5.",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "One of the greatest contributions 3D face databases offer is the inclusion of unconstrained head motion within space (for some examples see Figure 6 MPI; Kaulard et al., 2012; BP-4D-S; Zhang et al., 2014).",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "Exemplars of different FACS coded muscle activations, illustrating smiles, frowns and grimaces of deformable facial features are displayed in Figure 7.",
    "figure_references": [
      {
        "figure_number": "Figure 7",
        "panel": "",
        "figure_key": "figure_7"
      }
    ]
  },
  {
    "sentence": "For a more detailed overview of how facial information is captured with lighting or viewpoint camera arrays within these databases, see Figure 1.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "For example, the database presented in Figure 2B, experiences a loss of data from the posterior viewpoint of the head, which may impede studies examining VR environments (Bulthoff and Edelman, 1992; Stolz et al., 2019; Lamberti et al., 2020) or multiple viewpoints of a facial stimulus (Bülthoff et al., 2018; Abudarham et al., 2019; Zhan et al., 2019).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel B",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Overall, despite some remaining challenges, 3D and 4D facial capture and reconstruction has demonstrated that the unique facial features belonging to you and me, such as the cheeks, eyes and nose, can simulated on-screen in a highly realistic manner (see Figure 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Similarly, the dynamic video-recorded BU4D-S 4D database produced by Zhang et al. (2013, 2014) is the leading 4D database in citation count (Figure 3).",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      },
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "Search on 13/02/2020, including count of the original published journal article of each database.At first glance, the citation count pictured in Figure 4 appears impressive.",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Thus we examined logarithmic growth across academic fields below (Figure 5).",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      },
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "Search terms: (“allintitle, abstract or keywords”: “3-D face” OR “3D face” OR “three-dimensional face” OR “three-dimensional face” OR “4D”).FIGURE 5.",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "One of the greatest contributions 3D face databases offer is the inclusion of unconstrained head motion within space (for some examples see Figure 6 MPI; Kaulard et al., 2012; BP-4D-S; Zhang et al., 2014).",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "Exemplars of different FACS coded muscle activations, illustrating smiles, frowns and grimaces of deformable facial features are displayed in Figure 7.",
    "figure_references": [
      {
        "figure_number": "Figure 7",
        "panel": "",
        "figure_key": "figure_7"
      }
    ]
  },
  {
    "sentence": "For a more detailed overview of how facial information is captured with lighting or viewpoint camera arrays within these databases, see Figure 1.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "For example, the database presented in Figure 2B, experiences a loss of data from the posterior viewpoint of the head, which may impede studies examining VR environments (Bulthoff and Edelman, 1992; Stolz et al., 2019; Lamberti et al., 2020) or multiple viewpoints of a facial stimulus (Bülthoff et al., 2018; Abudarham et al., 2019; Zhan et al., 2019).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel B",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Overall, despite some remaining challenges, 3D and 4D facial capture and reconstruction has demonstrated that the unique facial features belonging to you and me, such as the cheeks, eyes and nose, can simulated on-screen in a highly realistic manner (see Figure 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Similarly, the dynamic video-recorded BU4D-S 4D database produced by Zhang et al. (2013, 2014) is the leading 4D database in citation count (Figure 3).",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      },
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "Search on 13/02/2020, including count of the original published journal article of each database.At first glance, the citation count pictured in Figure 4 appears impressive.",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Thus we examined logarithmic growth across academic fields below (Figure 5).",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      },
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "Search terms: (“allintitle, abstract or keywords”: “3-D face” OR “3D face” OR “three-dimensional face” OR “three-dimensional face” OR “4D”).FIGURE 5.",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "One of the greatest contributions 3D face databases offer is the inclusion of unconstrained head motion within space (for some examples see Figure 6 MPI; Kaulard et al., 2012; BP-4D-S; Zhang et al., 2014).",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "Exemplars of different FACS coded muscle activations, illustrating smiles, frowns and grimaces of deformable facial features are displayed in Figure 7.",
    "figure_references": [
      {
        "figure_number": "Figure 7",
        "panel": "",
        "figure_key": "figure_7"
      }
    ]
  },
  {
    "sentence": "For a more detailed overview of how facial information is captured with lighting or viewpoint camera arrays within these databases, see Figure 1.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "For example, the database presented in Figure 2B, experiences a loss of data from the posterior viewpoint of the head, which may impede studies examining VR environments (Bulthoff and Edelman, 1992; Stolz et al., 2019; Lamberti et al., 2020) or multiple viewpoints of a facial stimulus (Bülthoff et al., 2018; Abudarham et al., 2019; Zhan et al., 2019).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel B",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Overall, despite some remaining challenges, 3D and 4D facial capture and reconstruction has demonstrated that the unique facial features belonging to you and me, such as the cheeks, eyes and nose, can simulated on-screen in a highly realistic manner (see Figure 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Similarly, the dynamic video-recorded BU4D-S 4D database produced by Zhang et al. (2013, 2014) is the leading 4D database in citation count (Figure 3).",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      },
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "Search on 13/02/2020, including count of the original published journal article of each database.At first glance, the citation count pictured in Figure 4 appears impressive.",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Thus we examined logarithmic growth across academic fields below (Figure 5).",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      },
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "Search terms: (“allintitle, abstract or keywords”: “3-D face” OR “3D face” OR “three-dimensional face” OR “three-dimensional face” OR “4D”).FIGURE 5.",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "One of the greatest contributions 3D face databases offer is the inclusion of unconstrained head motion within space (for some examples see Figure 6 MPI; Kaulard et al., 2012; BP-4D-S; Zhang et al., 2014).",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "Exemplars of different FACS coded muscle activations, illustrating smiles, frowns and grimaces of deformable facial features are displayed in Figure 7.",
    "figure_references": [
      {
        "figure_number": "Figure 7",
        "panel": "",
        "figure_key": "figure_7"
      }
    ]
  },
  {
    "sentence": "For a more detailed overview of how facial information is captured with lighting or viewpoint camera arrays within these databases, see Figure 1.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "For example, the database presented in Figure 2B, experiences a loss of data from the posterior viewpoint of the head, which may impede studies examining VR environments (Bulthoff and Edelman, 1992; Stolz et al., 2019; Lamberti et al., 2020) or multiple viewpoints of a facial stimulus (Bülthoff et al., 2018; Abudarham et al., 2019; Zhan et al., 2019).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel B",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Overall, despite some remaining challenges, 3D and 4D facial capture and reconstruction has demonstrated that the unique facial features belonging to you and me, such as the cheeks, eyes and nose, can simulated on-screen in a highly realistic manner (see Figure 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Similarly, the dynamic video-recorded BU4D-S 4D database produced by Zhang et al. (2013, 2014) is the leading 4D database in citation count (Figure 3).",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      },
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "Search on 13/02/2020, including count of the original published journal article of each database.At first glance, the citation count pictured in Figure 4 appears impressive.",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Thus we examined logarithmic growth across academic fields below (Figure 5).",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      },
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "Search terms: (“allintitle, abstract or keywords”: “3-D face” OR “3D face” OR “three-dimensional face” OR “three-dimensional face” OR “4D”).FIGURE 5.",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "One of the greatest contributions 3D face databases offer is the inclusion of unconstrained head motion within space (for some examples see Figure 6 MPI; Kaulard et al., 2012; BP-4D-S; Zhang et al., 2014).",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "Exemplars of different FACS coded muscle activations, illustrating smiles, frowns and grimaces of deformable facial features are displayed in Figure 7.",
    "figure_references": [
      {
        "figure_number": "Figure 7",
        "panel": "",
        "figure_key": "figure_7"
      }
    ]
  },
  {
    "sentence": "For a more detailed overview of how facial information is captured with lighting or viewpoint camera arrays within these databases, see Figure 1.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "For example, the database presented in Figure 2B, experiences a loss of data from the posterior viewpoint of the head, which may impede studies examining VR environments (Bulthoff and Edelman, 1992; Stolz et al., 2019; Lamberti et al., 2020) or multiple viewpoints of a facial stimulus (Bülthoff et al., 2018; Abudarham et al., 2019; Zhan et al., 2019).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel B",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Overall, despite some remaining challenges, 3D and 4D facial capture and reconstruction has demonstrated that the unique facial features belonging to you and me, such as the cheeks, eyes and nose, can simulated on-screen in a highly realistic manner (see Figure 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "For a more detailed overview of how facial information is captured with lighting or viewpoint camera arrays within these databases, see Figure 1.",
    "figure_references": [
      {
        "figure_number": "Figure 1",
        "panel": "",
        "figure_key": "figure_1"
      }
    ]
  },
  {
    "sentence": "For example, the database presented in Figure 2B, experiences a loss of data from the posterior viewpoint of the head, which may impede studies examining VR environments (Bulthoff and Edelman, 1992; Stolz et al., 2019; Lamberti et al., 2020) or multiple viewpoints of a facial stimulus (Bülthoff et al., 2018; Abudarham et al., 2019; Zhan et al., 2019).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "Panel B",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Overall, despite some remaining challenges, 3D and 4D facial capture and reconstruction has demonstrated that the unique facial features belonging to you and me, such as the cheeks, eyes and nose, can simulated on-screen in a highly realistic manner (see Figure 2).",
    "figure_references": [
      {
        "figure_number": "Figure 2",
        "panel": "",
        "figure_key": "figure_2"
      }
    ]
  },
  {
    "sentence": "Similarly, the dynamic video-recorded BU4D-S 4D database produced by Zhang et al. (2013, 2014) is the leading 4D database in citation count (Figure 3).",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      },
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "Search on 13/02/2020, including count of the original published journal article of each database.At first glance, the citation count pictured in Figure 4 appears impressive.",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Thus we examined logarithmic growth across academic fields below (Figure 5).",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      },
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "Search terms: (“allintitle, abstract or keywords”: “3-D face” OR “3D face” OR “three-dimensional face” OR “three-dimensional face” OR “4D”).FIGURE 5.",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "Similarly, the dynamic video-recorded BU4D-S 4D database produced by Zhang et al. (2013, 2014) is the leading 4D database in citation count (Figure 3).",
    "figure_references": [
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      },
      {
        "figure_number": "Figure 3",
        "panel": "",
        "figure_key": "figure_3"
      }
    ]
  },
  {
    "sentence": "At first glance, the citation count pictured in Figure 4 appears impressive.",
    "figure_references": [
      {
        "figure_number": "Figure 4",
        "panel": "",
        "figure_key": "figure_4"
      }
    ]
  },
  {
    "sentence": "Thus we examined logarithmic growth across academic fields below (Figure 5).",
    "figure_references": [
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      },
      {
        "figure_number": "Figure 5",
        "panel": "",
        "figure_key": "figure_5"
      }
    ]
  },
  {
    "sentence": "One of the greatest contributions 3D face databases offer is the inclusion of unconstrained head motion within space (for some examples see Figure 6 MPI; Kaulard et al., 2012; BP-4D-S; Zhang et al., 2014).",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "Exemplars of different FACS coded muscle activations, illustrating smiles, frowns and grimaces of deformable facial features are displayed in Figure 7.",
    "figure_references": [
      {
        "figure_number": "Figure 7",
        "panel": "",
        "figure_key": "figure_7"
      }
    ]
  },
  {
    "sentence": "One of the greatest contributions 3D face databases offer is the inclusion of unconstrained head motion within space (for some examples see Figure 6 MPI; Kaulard et al., 2012; BP-4D-S; Zhang et al., 2014).",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "One of the greatest contributions 3D face databases offer is the inclusion of unconstrained head motion within space (for some examples see Figure 6 MPI; Kaulard et al., 2012; BP-4D-S; Zhang et al., 2014).",
    "figure_references": [
      {
        "figure_number": "Figure 6",
        "panel": "",
        "figure_key": "figure_6"
      }
    ]
  },
  {
    "sentence": "Exemplars of different FACS coded muscle activations, illustrating smiles, frowns and grimaces of deformable facial features are displayed in Figure 7.",
    "figure_references": [
      {
        "figure_number": "Figure 7",
        "panel": "",
        "figure_key": "figure_7"
      }
    ]
  },
  {
    "sentence": "Exemplars of different FACS coded muscle activations, illustrating smiles, frowns and grimaces of deformable facial features are displayed in Figure 7.",
    "figure_references": [
      {
        "figure_number": "Figure 7",
        "panel": "",
        "figure_key": "figure_7"
      }
    ]
  }
]