{
  "paper_id": "PMC10123086",
  "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10123086/",
  "figures": {
    "figure_1": {
      "figure_number": "Figure 1",
      "title": "Figure 1.",
      "caption": "In the 1980s, the cognitive and neural sciences were populated with linear stage-based “box-and-arrow” models of cognition. Cavanagh (1987) framed visual perception as a feedforward process of encapsulated visual feature modules sending their outputs to an integration process (A). Forster (1979) described language comprehension as a feedforward sequence of modules that did not allow feedback signals (B).",
      "possible_urls": [
        [
          "original_src",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/8fe250515c7e/nihms-1880297-f0001.jpg"
        ],
        [
          "large_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/8fe250515c7e/nihms-1880297-f0001.jpg?maxwidth=2000"
        ],
        [
          "original_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/8fe250515c7e/nihms-1880297-f0001.jpg?size=original"
        ],
        [
          "xlarge_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/8fe250515c7e/nihms-1880297-f0001.jpg?maxwidth=4000"
        ]
      ],
      "figure_id": "F1",
      "is_table": false,
      "working_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/8fe250515c7e/nihms-1880297-f0001.jpg",
      "download_success": true,
      "local_image_path": "./data/PMC10123086/images/figure_1.jpg",
      "final_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/8fe250515c7e/nihms-1880297-f0001.jpg"
    },
    "figure_2": {
      "figure_number": "Figure 2",
      "title": "Figure 2.",
      "caption": "In the 1990s, the cognitive and neural sciences began reporting a wide variety of context effects suggesting that the subsystems in Figure 1 are not as modular as once thought. Essentially, feedback and crosstalk arrows were added to the traditional box-and-arrow models to accommodate those findings, converting the framework into something befitting an interactive network. As a result, visual perception is now generally seen as a highly interactive process (Vinson et al., 2016) and so is language processing (Onnis & Spivey, 2012).",
      "possible_urls": [
        [
          "original_src",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/b9ea63a702e8/nihms-1880297-f0002.jpg"
        ],
        [
          "large_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/b9ea63a702e8/nihms-1880297-f0002.jpg?maxwidth=2000"
        ],
        [
          "original_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/b9ea63a702e8/nihms-1880297-f0002.jpg?size=original"
        ],
        [
          "xlarge_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/b9ea63a702e8/nihms-1880297-f0002.jpg?maxwidth=4000"
        ]
      ],
      "figure_id": "F2",
      "is_table": false,
      "working_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/b9ea63a702e8/nihms-1880297-f0002.jpg",
      "download_success": true,
      "local_image_path": "./data/PMC10123086/images/figure_2.jpg",
      "final_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/b9ea63a702e8/nihms-1880297-f0002.jpg"
    },
    "figure_5": {
      "figure_number": "Figure 5",
      "title": "Figure 5.",
      "caption": "With numerous effects of visual context on real-time language processing (Spivey, 2007), the schematic box-and-arrow models in Figure 2 might need to be enhanced with yet another arrow, connecting the visual system to the language system.",
      "possible_urls": [
        [
          "original_src",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/a373a4fc8a22/nihms-1880297-f0005.jpg"
        ],
        [
          "large_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/a373a4fc8a22/nihms-1880297-f0005.jpg?maxwidth=2000"
        ],
        [
          "original_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/a373a4fc8a22/nihms-1880297-f0005.jpg?size=original"
        ],
        [
          "xlarge_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/a373a4fc8a22/nihms-1880297-f0005.jpg?maxwidth=4000"
        ]
      ],
      "figure_id": "F5",
      "is_table": false,
      "working_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/a373a4fc8a22/nihms-1880297-f0005.jpg",
      "download_success": true,
      "local_image_path": "./data/PMC10123086/images/figure_5.jpg",
      "final_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/a373a4fc8a22/nihms-1880297-f0005.jpg"
    },
    "figure_6": {
      "figure_number": "Figure 6",
      "title": "Figure 6.",
      "caption": "With numerous effects of linguistic context on real-time visual processing (Spivey, 2007), the schematic box-and-arrow model in Figure 5 might need to update the arrow connecting the visual system and the language system to be bi-directional.",
      "possible_urls": [
        [
          "original_src",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/58863dd20329/nihms-1880297-f0006.jpg"
        ],
        [
          "large_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/58863dd20329/nihms-1880297-f0006.jpg?maxwidth=2000"
        ],
        [
          "original_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/58863dd20329/nihms-1880297-f0006.jpg?size=original"
        ],
        [
          "xlarge_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/58863dd20329/nihms-1880297-f0006.jpg?maxwidth=4000"
        ]
      ],
      "figure_id": "F6",
      "is_table": false,
      "working_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/58863dd20329/nihms-1880297-f0006.jpg",
      "download_success": true,
      "local_image_path": "./data/PMC10123086/images/figure_6.jpg",
      "final_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/58863dd20329/nihms-1880297-f0006.jpg"
    },
    "figure_7": {
      "figure_number": "Figure 7",
      "title": "Figure 7.",
      "caption": "In place of a box-and-arrow diagram, this “arrows-and-arrows” diagram may better depict the flexibility with which various cognitive processes can not only interact with each other but also reshape themselves.",
      "possible_urls": [
        [
          "original_src",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/92479de15682/nihms-1880297-f0007.jpg"
        ],
        [
          "large_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/92479de15682/nihms-1880297-f0007.jpg?maxwidth=2000"
        ],
        [
          "original_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/92479de15682/nihms-1880297-f0007.jpg?size=original"
        ],
        [
          "xlarge_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/92479de15682/nihms-1880297-f0007.jpg?maxwidth=4000"
        ]
      ],
      "figure_id": "F7",
      "is_table": false,
      "working_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/92479de15682/nihms-1880297-f0007.jpg",
      "download_success": true,
      "local_image_path": "./data/PMC10123086/images/figure_7.jpg",
      "final_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/92479de15682/nihms-1880297-f0007.jpg"
    },
    "figure_8": {
      "figure_number": "Figure 8",
      "title": "Figure 8.",
      "caption": "The cognitive system can temporarily reshape itself, via soft-assembly, to emphasize certain interactions (bold arrows) and de-emphasize others (dashed arrows). This schematic depiction of a soft-assembly might be for a cognitive system that is engaged in catching an American football while leaping in the air (or perhaps catching a bar of soap that’s trying to escape in the shower).",
      "possible_urls": [
        [
          "original_src",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/bc123ad94c20/nihms-1880297-f0008.jpg"
        ],
        [
          "large_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/bc123ad94c20/nihms-1880297-f0008.jpg?maxwidth=2000"
        ],
        [
          "original_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/bc123ad94c20/nihms-1880297-f0008.jpg?size=original"
        ],
        [
          "xlarge_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/bc123ad94c20/nihms-1880297-f0008.jpg?maxwidth=4000"
        ]
      ],
      "figure_id": "F8",
      "is_table": false,
      "working_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/bc123ad94c20/nihms-1880297-f0008.jpg",
      "download_success": true,
      "local_image_path": "./data/PMC10123086/images/figure_8.jpg",
      "final_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/bc123ad94c20/nihms-1880297-f0008.jpg"
    },
    "figure_9": {
      "figure_number": "Figure 9",
      "title": "Figure 9.",
      "caption": "The cognitive system can temporarily reshape itself, via soft-assembly, to emphasize certain interactions (bold arrows) and de-emphasize others (dashed arrows). This schematic depiction of a soft-assembly might be for a cognitive system that is engaged in silently reading a journal article.",
      "possible_urls": [
        [
          "original_src",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/c0242fb9a208/nihms-1880297-f0009.jpg"
        ],
        [
          "large_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/c0242fb9a208/nihms-1880297-f0009.jpg?maxwidth=2000"
        ],
        [
          "original_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/c0242fb9a208/nihms-1880297-f0009.jpg?size=original"
        ],
        [
          "xlarge_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/c0242fb9a208/nihms-1880297-f0009.jpg?maxwidth=4000"
        ]
      ],
      "figure_id": "F9",
      "is_table": false,
      "working_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/c0242fb9a208/nihms-1880297-f0009.jpg",
      "download_success": true,
      "local_image_path": "./data/PMC10123086/images/figure_9.jpg",
      "final_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/c0242fb9a208/nihms-1880297-f0009.jpg"
    },
    "figure_10": {
      "figure_number": "Figure 10",
      "title": "Figure 10.",
      "caption": "These three slightly different theoretical frameworks operating at the cutting edge of contemporary cognitive science all can be seen as interactive frameworks that combine many contextual factors at once to convert sensory input into mental states and/or actions. (A) Bayesian approaches emphasize static internal mental representations that have probabilities associated with them. (B) Dynamical systems approaches emphasize temporally dynamic trajectories on a state-space manifold that may include both neural and non-neural parameters. (C) Neural network approaches emphasize roughly neurally plausible simulations of the relationships between sensory input, cognitive processes, and motor output.",
      "possible_urls": [
        [
          "original_src",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/a2146608b46b/nihms-1880297-f0010.jpg"
        ],
        [
          "large_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/a2146608b46b/nihms-1880297-f0010.jpg?maxwidth=2000"
        ],
        [
          "original_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/a2146608b46b/nihms-1880297-f0010.jpg?size=original"
        ],
        [
          "xlarge_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/a2146608b46b/nihms-1880297-f0010.jpg?maxwidth=4000"
        ]
      ],
      "figure_id": "F10",
      "is_table": false,
      "working_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/a2146608b46b/nihms-1880297-f0010.jpg",
      "download_success": true,
      "local_image_path": "./data/PMC10123086/images/figure_10.jpg",
      "final_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/a2146608b46b/nihms-1880297-f0010.jpg"
    },
    "figure_11": {
      "figure_number": "Figure 11",
      "title": "Figure 11.",
      "caption": "An abstract depiction of the relationship between higher-level, mid-level, and lower-level theoretical frameworks. In this perspective, different levels are allowed to have their own idiosyncratic theoretical constructs (i.e., shapes), however, it is crucial that they connect with adjacent levels at least enough to confirm some degree of compatibility between those constructs.",
      "possible_urls": [
        [
          "original_src",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/68331522d765/nihms-1880297-f0011.jpg"
        ],
        [
          "large_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/68331522d765/nihms-1880297-f0011.jpg?maxwidth=2000"
        ],
        [
          "original_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/68331522d765/nihms-1880297-f0011.jpg?size=original"
        ],
        [
          "xlarge_size",
          "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/68331522d765/nihms-1880297-f0011.jpg?maxwidth=4000"
        ]
      ],
      "figure_id": "F11",
      "is_table": false,
      "working_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/68331522d765/nihms-1880297-f0011.jpg",
      "download_success": true,
      "local_image_path": "./data/PMC10123086/images/figure_11.jpg",
      "final_url": "https://cdn.ncbi.nlm.nih.gov/pmc/blobs/a117/10123086/68331522d765/nihms-1880297-f0011.jpg"
    }
  },
  "claims": [
    {
      "sentence": "However, they often made predictions that immediate context effects (e.g., color influencing motion perception or pragmatics influencing syntax) should be impossible (see Figure 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nIn the 1990s, the cognitive and neural sciences began reporting a wide variety of context effects suggesting that the subsystems in Figure 1 are not as modular as once thought.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "To examine spoken word recognition, we presented participants with a table containing small objects and toys (Figure 3) and gave them live spoken instructions (e.g., “Pick up the candy.”) while the headband-mounted eyetracker recorded their eye movements.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "A “cohort” refers to a word that shares several initial phonemes with the word that is being spoken (Marslen-Wilson, 1987). (Additional targets and cohorts included penny/pencil, car/carton, etc.)\nFigure 3.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith a display of several real objects on a table, a participant might be instructed to “Pick up the candy.” Since the object to the right of the candy has a typical name that uses the same first four phonemes, /candle/, participants often looked at it briefly before making a corrective saccade to fixate the piece of candy.When the cohort object was present on the table (Figure 3), participants made a brief saccade to it about 25% of the time before then making a corrective saccade to the target object.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Is the apple supposed to be put on the towel or into the box? At the moment when all the listener has heard so far is “Put the apple on the towel…”, there may be a temptation to interpret the extra towel in the visual display (top right of Figure 4) as the destination for the apple’s movement.",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "A completely different sensory system, vision, can influence the language system (see Figure 5).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith numerous effects of visual context on real-time language processing (Spivey, 2007), the schematic box-and-arrow models in Figure 2 might need to be enhanced with yet another arrow, connecting the visual system to the language system.Language Comprehension Influences Visual Perception\nEberhard et al.’s (1995) results of anticipatory reference resolution contributed to the evidence for predictive processing as a fundamental component in theories of real-time language comprehension (e.g., Elman, 1990; Dikker & Pylkkänen, 2013; Kamide, Altmann, & Haywood, 2003; Ryskin, Ng, Mimnaugh, Brown-Schmidt, & Federmeier, 2020) – even if these “predictions” may be nothing more than the emergent result of a multiscale pattern completion process (Falandays, Nguyen, & Spivey, 2021).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "With vision influencing language and language influencing vision (Anderson, Chiu, Huette & Spivey, 2011), perhaps it is worthwhile to slightly modify the schematic box-and-arrow diagram from Figure 5 with a bi-directional arrow connecting the visual system and the language system together (see Figure 6).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        },
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Although the progression from Figures 1, 2 and 5 to Figure 6 could give one the impression that we should take an existing model of language processing and an existing model of visual processing and simply connect them, that is surely not the optimal solution.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Importantly, as we continue to see arrows added to this old-fashioned diagram (e.g., Figure 6), it can start to look like the arrows might be “doing more work” than the boxes are (see Onnis & Spivey, 2012).",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith numerous effects of linguistic context on real-time visual processing (Spivey, 2007), the schematic box-and-arrow model in Figure 5 might need to update the arrow connecting the visual system and the language system to be bi-directional.Embodied Cognition\nWhen the arrows are explaining more of the phenomena than the boxes are, the late great Guy Van Orden referred to this as interaction-dominant dynamics (Van Orden, Holden, & Turvey, 2003).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "He contrasted it with the component-dominant dynamics of traditional linear feedforward modular models of cognition (recall Figure 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This is exactly what one would expect if the function of the language system was not isolable from the function of the visual system (e.g., Figure 6).",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Take, for example, the visual world paradigm experiment where participants were instructed to “Put the apple on the towel in the box” (Figure 4).",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "With such a tight relationship between language, vision and action, it should come as no surprise that we were able to replicate the eye movement results for spoken word recognition (Figure 3) and syntactic ambiguity resolution (Figure 4) with a computer-mouse movement task.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "For example, Figure 7 modifies Figure 6 by removing the pretense that language, vision and action processes have any kind of crisp discrete boundaries that delineate them from one another.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        },
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "There are still more coupling processes (i.e., arrows) internal to the language-like capacity in Figure 7 than there are coupling processes that connect it to the other capacities.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "The schematic diagram in Figure 7 can be softly assembled to reshape the system so that it is temporarily dedicated to one type of task or another.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "For instance, in Figure 8, the system has softly (temporarily) assembled itself into functioning mostly as a sensorimotor processing system by boosting the coupling of its vision and action processes and damping the coupling of the language processes.",
      "figure_references": [
        {
          "figure_number": "Figure 8",
          "panel": "",
          "figure_key": "figure_8"
        }
      ]
    },
    {
      "sentence": "Compare that soft assembly with the one in Figure 9, where the system has softly (temporarily) assembled itself into functioning mostly as a visuolinguistic processing system by boosting the coupling of some of its vision and language processes and damping the coupling of the action processes.",
      "figure_references": [
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "This schematic depiction of a soft-assembly might be for a cognitive system that is engaged in catching an American football while leaping in the air (or perhaps catching a bar of soap that’s trying to escape in the shower).Figure 9.",
      "figure_references": [
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "Rather than treating language as something for which the brain has dedicated processors that are hard-wired to function a certain way (e.g., Figure 1B), perhaps we should treat language as something that emerges from the self-organization capabilities of some brains-and-bodies performing actions together in a particular environment (e.g., Figure 7).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "Panel B",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "I have traced the epistemic progression from box-and-arrow diagrams of cognition that prevented context effects (Figure 1) to box-and-arrow diagrams that allow context effects (Figures 2, 5 and 6) and eventually to “arrows-and-arrows” diagrams that not only embrace context effects but even encourage the occasional blurring of the distinctions between traditional cognitive faculties (Figures 7–9).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This essay began by noting that box-and-arrow models have given way to “a few slightly different theoretical approaches that all readily incorporate immediate context effects.” Three of those theoretical approaches are worth noting here: Bayesian models, dynamical system theory, and artificial neural networks (Figure 10).",
      "figure_references": [
        {
          "figure_number": "Figure 10",
          "panel": "",
          "figure_key": "figure_10"
        },
        {
          "figure_number": "Figure 10",
          "panel": "",
          "figure_key": "figure_10"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nThese three slightly different theoretical frameworks operating at the cutting edge of contemporary cognitive science all can be seen as interactive frameworks that combine many contextual factors at once to convert sensory input into mental states and/or actions. (A) Bayesian approaches emphasize static internal mental representations that have probabilities associated with them. (B) Dynamical systems approaches emphasize temporally dynamic trajectories on a state-space manifold that may include both neural and non-neural parameters. (C) Neural network approaches emphasize roughly neurally plausible simulations of the relationships between sensory input, cognitive processes, and motor output.Rather than being adversaries, these different theoretical frameworks can, in principle, cooperate with one another in scientifically identifying the coherent bundle of internal causal forces that make a cognitive process warrant its own label (instead of relying on folk psychology), and also in determining how weakly or strongly one cognitive process influences another (see the bundles of arrows with labels in Figure 7).",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "Abstractly depicted at the top of Figure 11, we can imagine how individual minds (the pentagonal shapes) might fit together to form a social group.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "The pentagonal shapes at the social level of analysis (top of Figure 11) need not be made of smaller pentagonal shapes at the cognitive level; and those micro-pentagonal shapes wouldn’t need to be made of nano-pentagonal shapes at the neural level.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "Essentially, those “puzzle pieces” in Figure 11 had better be able to combine in ways that can indeed form one of those “asymmetric pentagons” above them.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "Essentially, if one’s theory says that the puzzle pieces in Figure 11 are made of sub-elements that do not look or behave at all like hexagons, then that theory about puzzle pieces might be impossible.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "And thus, as suggested back in Figure 7, perhaps our models (and even Figure 11 itself) should be made entirely of arrows (relations), with no closed polygons (objects) at all.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        },
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "However, they often made predictions that immediate context effects (e.g., color influencing motion perception or pragmatics influencing syntax) should be impossible (see Figure 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nIn the 1990s, the cognitive and neural sciences began reporting a wide variety of context effects suggesting that the subsystems in Figure 1 are not as modular as once thought.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "To examine spoken word recognition, we presented participants with a table containing small objects and toys (Figure 3) and gave them live spoken instructions (e.g., “Pick up the candy.”) while the headband-mounted eyetracker recorded their eye movements.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "A “cohort” refers to a word that shares several initial phonemes with the word that is being spoken (Marslen-Wilson, 1987). (Additional targets and cohorts included penny/pencil, car/carton, etc.)\nFigure 3.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith a display of several real objects on a table, a participant might be instructed to “Pick up the candy.” Since the object to the right of the candy has a typical name that uses the same first four phonemes, /candle/, participants often looked at it briefly before making a corrective saccade to fixate the piece of candy.When the cohort object was present on the table (Figure 3), participants made a brief saccade to it about 25% of the time before then making a corrective saccade to the target object.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Is the apple supposed to be put on the towel or into the box? At the moment when all the listener has heard so far is “Put the apple on the towel…”, there may be a temptation to interpret the extra towel in the visual display (top right of Figure 4) as the destination for the apple’s movement.",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "A completely different sensory system, vision, can influence the language system (see Figure 5).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith numerous effects of visual context on real-time language processing (Spivey, 2007), the schematic box-and-arrow models in Figure 2 might need to be enhanced with yet another arrow, connecting the visual system to the language system.Language Comprehension Influences Visual Perception\nEberhard et al.’s (1995) results of anticipatory reference resolution contributed to the evidence for predictive processing as a fundamental component in theories of real-time language comprehension (e.g., Elman, 1990; Dikker & Pylkkänen, 2013; Kamide, Altmann, & Haywood, 2003; Ryskin, Ng, Mimnaugh, Brown-Schmidt, & Federmeier, 2020) – even if these “predictions” may be nothing more than the emergent result of a multiscale pattern completion process (Falandays, Nguyen, & Spivey, 2021).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "With vision influencing language and language influencing vision (Anderson, Chiu, Huette & Spivey, 2011), perhaps it is worthwhile to slightly modify the schematic box-and-arrow diagram from Figure 5 with a bi-directional arrow connecting the visual system and the language system together (see Figure 6).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        },
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Although the progression from Figures 1, 2 and 5 to Figure 6 could give one the impression that we should take an existing model of language processing and an existing model of visual processing and simply connect them, that is surely not the optimal solution.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Importantly, as we continue to see arrows added to this old-fashioned diagram (e.g., Figure 6), it can start to look like the arrows might be “doing more work” than the boxes are (see Onnis & Spivey, 2012).",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith numerous effects of linguistic context on real-time visual processing (Spivey, 2007), the schematic box-and-arrow model in Figure 5 might need to update the arrow connecting the visual system and the language system to be bi-directional.Embodied Cognition\nWhen the arrows are explaining more of the phenomena than the boxes are, the late great Guy Van Orden referred to this as interaction-dominant dynamics (Van Orden, Holden, & Turvey, 2003).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "He contrasted it with the component-dominant dynamics of traditional linear feedforward modular models of cognition (recall Figure 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This is exactly what one would expect if the function of the language system was not isolable from the function of the visual system (e.g., Figure 6).",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Take, for example, the visual world paradigm experiment where participants were instructed to “Put the apple on the towel in the box” (Figure 4).",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "With such a tight relationship between language, vision and action, it should come as no surprise that we were able to replicate the eye movement results for spoken word recognition (Figure 3) and syntactic ambiguity resolution (Figure 4) with a computer-mouse movement task.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "For example, Figure 7 modifies Figure 6 by removing the pretense that language, vision and action processes have any kind of crisp discrete boundaries that delineate them from one another.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        },
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "There are still more coupling processes (i.e., arrows) internal to the language-like capacity in Figure 7 than there are coupling processes that connect it to the other capacities.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "The schematic diagram in Figure 7 can be softly assembled to reshape the system so that it is temporarily dedicated to one type of task or another.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "For instance, in Figure 8, the system has softly (temporarily) assembled itself into functioning mostly as a sensorimotor processing system by boosting the coupling of its vision and action processes and damping the coupling of the language processes.",
      "figure_references": [
        {
          "figure_number": "Figure 8",
          "panel": "",
          "figure_key": "figure_8"
        }
      ]
    },
    {
      "sentence": "Compare that soft assembly with the one in Figure 9, where the system has softly (temporarily) assembled itself into functioning mostly as a visuolinguistic processing system by boosting the coupling of some of its vision and language processes and damping the coupling of the action processes.",
      "figure_references": [
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "This schematic depiction of a soft-assembly might be for a cognitive system that is engaged in catching an American football while leaping in the air (or perhaps catching a bar of soap that’s trying to escape in the shower).Figure 9.",
      "figure_references": [
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "Rather than treating language as something for which the brain has dedicated processors that are hard-wired to function a certain way (e.g., Figure 1B), perhaps we should treat language as something that emerges from the self-organization capabilities of some brains-and-bodies performing actions together in a particular environment (e.g., Figure 7).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "Panel B",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "I have traced the epistemic progression from box-and-arrow diagrams of cognition that prevented context effects (Figure 1) to box-and-arrow diagrams that allow context effects (Figures 2, 5 and 6) and eventually to “arrows-and-arrows” diagrams that not only embrace context effects but even encourage the occasional blurring of the distinctions between traditional cognitive faculties (Figures 7–9).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This essay began by noting that box-and-arrow models have given way to “a few slightly different theoretical approaches that all readily incorporate immediate context effects.” Three of those theoretical approaches are worth noting here: Bayesian models, dynamical system theory, and artificial neural networks (Figure 10).",
      "figure_references": [
        {
          "figure_number": "Figure 10",
          "panel": "",
          "figure_key": "figure_10"
        },
        {
          "figure_number": "Figure 10",
          "panel": "",
          "figure_key": "figure_10"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nThese three slightly different theoretical frameworks operating at the cutting edge of contemporary cognitive science all can be seen as interactive frameworks that combine many contextual factors at once to convert sensory input into mental states and/or actions. (A) Bayesian approaches emphasize static internal mental representations that have probabilities associated with them. (B) Dynamical systems approaches emphasize temporally dynamic trajectories on a state-space manifold that may include both neural and non-neural parameters. (C) Neural network approaches emphasize roughly neurally plausible simulations of the relationships between sensory input, cognitive processes, and motor output.Rather than being adversaries, these different theoretical frameworks can, in principle, cooperate with one another in scientifically identifying the coherent bundle of internal causal forces that make a cognitive process warrant its own label (instead of relying on folk psychology), and also in determining how weakly or strongly one cognitive process influences another (see the bundles of arrows with labels in Figure 7).",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "Abstractly depicted at the top of Figure 11, we can imagine how individual minds (the pentagonal shapes) might fit together to form a social group.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "The pentagonal shapes at the social level of analysis (top of Figure 11) need not be made of smaller pentagonal shapes at the cognitive level; and those micro-pentagonal shapes wouldn’t need to be made of nano-pentagonal shapes at the neural level.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "Essentially, those “puzzle pieces” in Figure 11 had better be able to combine in ways that can indeed form one of those “asymmetric pentagons” above them.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "Essentially, if one’s theory says that the puzzle pieces in Figure 11 are made of sub-elements that do not look or behave at all like hexagons, then that theory about puzzle pieces might be impossible.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "And thus, as suggested back in Figure 7, perhaps our models (and even Figure 11 itself) should be made entirely of arrows (relations), with no closed polygons (objects) at all.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        },
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "However, they often made predictions that immediate context effects (e.g., color influencing motion perception or pragmatics influencing syntax) should be impossible (see Figure 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nIn the 1990s, the cognitive and neural sciences began reporting a wide variety of context effects suggesting that the subsystems in Figure 1 are not as modular as once thought.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "To examine spoken word recognition, we presented participants with a table containing small objects and toys (Figure 3) and gave them live spoken instructions (e.g., “Pick up the candy.”) while the headband-mounted eyetracker recorded their eye movements.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "A “cohort” refers to a word that shares several initial phonemes with the word that is being spoken (Marslen-Wilson, 1987). (Additional targets and cohorts included penny/pencil, car/carton, etc.)\nFigure 3.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith a display of several real objects on a table, a participant might be instructed to “Pick up the candy.” Since the object to the right of the candy has a typical name that uses the same first four phonemes, /candle/, participants often looked at it briefly before making a corrective saccade to fixate the piece of candy.When the cohort object was present on the table (Figure 3), participants made a brief saccade to it about 25% of the time before then making a corrective saccade to the target object.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Is the apple supposed to be put on the towel or into the box? At the moment when all the listener has heard so far is “Put the apple on the towel…”, there may be a temptation to interpret the extra towel in the visual display (top right of Figure 4) as the destination for the apple’s movement.",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "A completely different sensory system, vision, can influence the language system (see Figure 5).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith numerous effects of visual context on real-time language processing (Spivey, 2007), the schematic box-and-arrow models in Figure 2 might need to be enhanced with yet another arrow, connecting the visual system to the language system.Language Comprehension Influences Visual Perception\nEberhard et al.’s (1995) results of anticipatory reference resolution contributed to the evidence for predictive processing as a fundamental component in theories of real-time language comprehension (e.g., Elman, 1990; Dikker & Pylkkänen, 2013; Kamide, Altmann, & Haywood, 2003; Ryskin, Ng, Mimnaugh, Brown-Schmidt, & Federmeier, 2020) – even if these “predictions” may be nothing more than the emergent result of a multiscale pattern completion process (Falandays, Nguyen, & Spivey, 2021).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "With vision influencing language and language influencing vision (Anderson, Chiu, Huette & Spivey, 2011), perhaps it is worthwhile to slightly modify the schematic box-and-arrow diagram from Figure 5 with a bi-directional arrow connecting the visual system and the language system together (see Figure 6).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        },
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Although the progression from Figures 1, 2 and 5 to Figure 6 could give one the impression that we should take an existing model of language processing and an existing model of visual processing and simply connect them, that is surely not the optimal solution.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Importantly, as we continue to see arrows added to this old-fashioned diagram (e.g., Figure 6), it can start to look like the arrows might be “doing more work” than the boxes are (see Onnis & Spivey, 2012).",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith numerous effects of linguistic context on real-time visual processing (Spivey, 2007), the schematic box-and-arrow model in Figure 5 might need to update the arrow connecting the visual system and the language system to be bi-directional.Embodied Cognition\nWhen the arrows are explaining more of the phenomena than the boxes are, the late great Guy Van Orden referred to this as interaction-dominant dynamics (Van Orden, Holden, & Turvey, 2003).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "He contrasted it with the component-dominant dynamics of traditional linear feedforward modular models of cognition (recall Figure 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This is exactly what one would expect if the function of the language system was not isolable from the function of the visual system (e.g., Figure 6).",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Take, for example, the visual world paradigm experiment where participants were instructed to “Put the apple on the towel in the box” (Figure 4).",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "With such a tight relationship between language, vision and action, it should come as no surprise that we were able to replicate the eye movement results for spoken word recognition (Figure 3) and syntactic ambiguity resolution (Figure 4) with a computer-mouse movement task.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "For example, Figure 7 modifies Figure 6 by removing the pretense that language, vision and action processes have any kind of crisp discrete boundaries that delineate them from one another.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        },
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "There are still more coupling processes (i.e., arrows) internal to the language-like capacity in Figure 7 than there are coupling processes that connect it to the other capacities.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "The schematic diagram in Figure 7 can be softly assembled to reshape the system so that it is temporarily dedicated to one type of task or another.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "For instance, in Figure 8, the system has softly (temporarily) assembled itself into functioning mostly as a sensorimotor processing system by boosting the coupling of its vision and action processes and damping the coupling of the language processes.",
      "figure_references": [
        {
          "figure_number": "Figure 8",
          "panel": "",
          "figure_key": "figure_8"
        }
      ]
    },
    {
      "sentence": "Compare that soft assembly with the one in Figure 9, where the system has softly (temporarily) assembled itself into functioning mostly as a visuolinguistic processing system by boosting the coupling of some of its vision and language processes and damping the coupling of the action processes.",
      "figure_references": [
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "This schematic depiction of a soft-assembly might be for a cognitive system that is engaged in catching an American football while leaping in the air (or perhaps catching a bar of soap that’s trying to escape in the shower).Figure 9.",
      "figure_references": [
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "Rather than treating language as something for which the brain has dedicated processors that are hard-wired to function a certain way (e.g., Figure 1B), perhaps we should treat language as something that emerges from the self-organization capabilities of some brains-and-bodies performing actions together in a particular environment (e.g., Figure 7).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "Panel B",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "I have traced the epistemic progression from box-and-arrow diagrams of cognition that prevented context effects (Figure 1) to box-and-arrow diagrams that allow context effects (Figures 2, 5 and 6) and eventually to “arrows-and-arrows” diagrams that not only embrace context effects but even encourage the occasional blurring of the distinctions between traditional cognitive faculties (Figures 7–9).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This essay began by noting that box-and-arrow models have given way to “a few slightly different theoretical approaches that all readily incorporate immediate context effects.” Three of those theoretical approaches are worth noting here: Bayesian models, dynamical system theory, and artificial neural networks (Figure 10).",
      "figure_references": [
        {
          "figure_number": "Figure 10",
          "panel": "",
          "figure_key": "figure_10"
        },
        {
          "figure_number": "Figure 10",
          "panel": "",
          "figure_key": "figure_10"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nThese three slightly different theoretical frameworks operating at the cutting edge of contemporary cognitive science all can be seen as interactive frameworks that combine many contextual factors at once to convert sensory input into mental states and/or actions. (A) Bayesian approaches emphasize static internal mental representations that have probabilities associated with them. (B) Dynamical systems approaches emphasize temporally dynamic trajectories on a state-space manifold that may include both neural and non-neural parameters. (C) Neural network approaches emphasize roughly neurally plausible simulations of the relationships between sensory input, cognitive processes, and motor output.Rather than being adversaries, these different theoretical frameworks can, in principle, cooperate with one another in scientifically identifying the coherent bundle of internal causal forces that make a cognitive process warrant its own label (instead of relying on folk psychology), and also in determining how weakly or strongly one cognitive process influences another (see the bundles of arrows with labels in Figure 7).",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "Abstractly depicted at the top of Figure 11, we can imagine how individual minds (the pentagonal shapes) might fit together to form a social group.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "The pentagonal shapes at the social level of analysis (top of Figure 11) need not be made of smaller pentagonal shapes at the cognitive level; and those micro-pentagonal shapes wouldn’t need to be made of nano-pentagonal shapes at the neural level.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "Essentially, those “puzzle pieces” in Figure 11 had better be able to combine in ways that can indeed form one of those “asymmetric pentagons” above them.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "Essentially, if one’s theory says that the puzzle pieces in Figure 11 are made of sub-elements that do not look or behave at all like hexagons, then that theory about puzzle pieces might be impossible.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "And thus, as suggested back in Figure 7, perhaps our models (and even Figure 11 itself) should be made entirely of arrows (relations), with no closed polygons (objects) at all.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        },
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "However, they often made predictions that immediate context effects (e.g., color influencing motion perception or pragmatics influencing syntax) should be impossible (see Figure 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nIn the 1990s, the cognitive and neural sciences began reporting a wide variety of context effects suggesting that the subsystems in Figure 1 are not as modular as once thought.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "To examine spoken word recognition, we presented participants with a table containing small objects and toys (Figure 3) and gave them live spoken instructions (e.g., “Pick up the candy.”) while the headband-mounted eyetracker recorded their eye movements.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "A “cohort” refers to a word that shares several initial phonemes with the word that is being spoken (Marslen-Wilson, 1987). (Additional targets and cohorts included penny/pencil, car/carton, etc.)\nFigure 3.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith a display of several real objects on a table, a participant might be instructed to “Pick up the candy.” Since the object to the right of the candy has a typical name that uses the same first four phonemes, /candle/, participants often looked at it briefly before making a corrective saccade to fixate the piece of candy.When the cohort object was present on the table (Figure 3), participants made a brief saccade to it about 25% of the time before then making a corrective saccade to the target object.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Is the apple supposed to be put on the towel or into the box? At the moment when all the listener has heard so far is “Put the apple on the towel…”, there may be a temptation to interpret the extra towel in the visual display (top right of Figure 4) as the destination for the apple’s movement.",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "A completely different sensory system, vision, can influence the language system (see Figure 5).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith numerous effects of visual context on real-time language processing (Spivey, 2007), the schematic box-and-arrow models in Figure 2 might need to be enhanced with yet another arrow, connecting the visual system to the language system.Language Comprehension Influences Visual Perception\nEberhard et al.’s (1995) results of anticipatory reference resolution contributed to the evidence for predictive processing as a fundamental component in theories of real-time language comprehension (e.g., Elman, 1990; Dikker & Pylkkänen, 2013; Kamide, Altmann, & Haywood, 2003; Ryskin, Ng, Mimnaugh, Brown-Schmidt, & Federmeier, 2020) – even if these “predictions” may be nothing more than the emergent result of a multiscale pattern completion process (Falandays, Nguyen, & Spivey, 2021).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "With vision influencing language and language influencing vision (Anderson, Chiu, Huette & Spivey, 2011), perhaps it is worthwhile to slightly modify the schematic box-and-arrow diagram from Figure 5 with a bi-directional arrow connecting the visual system and the language system together (see Figure 6).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        },
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Although the progression from Figures 1, 2 and 5 to Figure 6 could give one the impression that we should take an existing model of language processing and an existing model of visual processing and simply connect them, that is surely not the optimal solution.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Importantly, as we continue to see arrows added to this old-fashioned diagram (e.g., Figure 6), it can start to look like the arrows might be “doing more work” than the boxes are (see Onnis & Spivey, 2012).",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith numerous effects of linguistic context on real-time visual processing (Spivey, 2007), the schematic box-and-arrow model in Figure 5 might need to update the arrow connecting the visual system and the language system to be bi-directional.Embodied Cognition\nWhen the arrows are explaining more of the phenomena than the boxes are, the late great Guy Van Orden referred to this as interaction-dominant dynamics (Van Orden, Holden, & Turvey, 2003).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "He contrasted it with the component-dominant dynamics of traditional linear feedforward modular models of cognition (recall Figure 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This is exactly what one would expect if the function of the language system was not isolable from the function of the visual system (e.g., Figure 6).",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Take, for example, the visual world paradigm experiment where participants were instructed to “Put the apple on the towel in the box” (Figure 4).",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "With such a tight relationship between language, vision and action, it should come as no surprise that we were able to replicate the eye movement results for spoken word recognition (Figure 3) and syntactic ambiguity resolution (Figure 4) with a computer-mouse movement task.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "For example, Figure 7 modifies Figure 6 by removing the pretense that language, vision and action processes have any kind of crisp discrete boundaries that delineate them from one another.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        },
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "There are still more coupling processes (i.e., arrows) internal to the language-like capacity in Figure 7 than there are coupling processes that connect it to the other capacities.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "The schematic diagram in Figure 7 can be softly assembled to reshape the system so that it is temporarily dedicated to one type of task or another.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "For instance, in Figure 8, the system has softly (temporarily) assembled itself into functioning mostly as a sensorimotor processing system by boosting the coupling of its vision and action processes and damping the coupling of the language processes.",
      "figure_references": [
        {
          "figure_number": "Figure 8",
          "panel": "",
          "figure_key": "figure_8"
        }
      ]
    },
    {
      "sentence": "Compare that soft assembly with the one in Figure 9, where the system has softly (temporarily) assembled itself into functioning mostly as a visuolinguistic processing system by boosting the coupling of some of its vision and language processes and damping the coupling of the action processes.",
      "figure_references": [
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "This schematic depiction of a soft-assembly might be for a cognitive system that is engaged in catching an American football while leaping in the air (or perhaps catching a bar of soap that’s trying to escape in the shower).Figure 9.",
      "figure_references": [
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "Rather than treating language as something for which the brain has dedicated processors that are hard-wired to function a certain way (e.g., Figure 1B), perhaps we should treat language as something that emerges from the self-organization capabilities of some brains-and-bodies performing actions together in a particular environment (e.g., Figure 7).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "Panel B",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "I have traced the epistemic progression from box-and-arrow diagrams of cognition that prevented context effects (Figure 1) to box-and-arrow diagrams that allow context effects (Figures 2, 5 and 6) and eventually to “arrows-and-arrows” diagrams that not only embrace context effects but even encourage the occasional blurring of the distinctions between traditional cognitive faculties (Figures 7–9).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This essay began by noting that box-and-arrow models have given way to “a few slightly different theoretical approaches that all readily incorporate immediate context effects.” Three of those theoretical approaches are worth noting here: Bayesian models, dynamical system theory, and artificial neural networks (Figure 10).",
      "figure_references": [
        {
          "figure_number": "Figure 10",
          "panel": "",
          "figure_key": "figure_10"
        },
        {
          "figure_number": "Figure 10",
          "panel": "",
          "figure_key": "figure_10"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nThese three slightly different theoretical frameworks operating at the cutting edge of contemporary cognitive science all can be seen as interactive frameworks that combine many contextual factors at once to convert sensory input into mental states and/or actions. (A) Bayesian approaches emphasize static internal mental representations that have probabilities associated with them. (B) Dynamical systems approaches emphasize temporally dynamic trajectories on a state-space manifold that may include both neural and non-neural parameters. (C) Neural network approaches emphasize roughly neurally plausible simulations of the relationships between sensory input, cognitive processes, and motor output.Rather than being adversaries, these different theoretical frameworks can, in principle, cooperate with one another in scientifically identifying the coherent bundle of internal causal forces that make a cognitive process warrant its own label (instead of relying on folk psychology), and also in determining how weakly or strongly one cognitive process influences another (see the bundles of arrows with labels in Figure 7).",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "Abstractly depicted at the top of Figure 11, we can imagine how individual minds (the pentagonal shapes) might fit together to form a social group.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "The pentagonal shapes at the social level of analysis (top of Figure 11) need not be made of smaller pentagonal shapes at the cognitive level; and those micro-pentagonal shapes wouldn’t need to be made of nano-pentagonal shapes at the neural level.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "Essentially, those “puzzle pieces” in Figure 11 had better be able to combine in ways that can indeed form one of those “asymmetric pentagons” above them.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "Essentially, if one’s theory says that the puzzle pieces in Figure 11 are made of sub-elements that do not look or behave at all like hexagons, then that theory about puzzle pieces might be impossible.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "And thus, as suggested back in Figure 7, perhaps our models (and even Figure 11 itself) should be made entirely of arrows (relations), with no closed polygons (objects) at all.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        },
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "However, they often made predictions that immediate context effects (e.g., color influencing motion perception or pragmatics influencing syntax) should be impossible (see Figure 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nIn the 1990s, the cognitive and neural sciences began reporting a wide variety of context effects suggesting that the subsystems in Figure 1 are not as modular as once thought.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "To examine spoken word recognition, we presented participants with a table containing small objects and toys (Figure 3) and gave them live spoken instructions (e.g., “Pick up the candy.”) while the headband-mounted eyetracker recorded their eye movements.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "A “cohort” refers to a word that shares several initial phonemes with the word that is being spoken (Marslen-Wilson, 1987). (Additional targets and cohorts included penny/pencil, car/carton, etc.)\nFigure 3.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith a display of several real objects on a table, a participant might be instructed to “Pick up the candy.” Since the object to the right of the candy has a typical name that uses the same first four phonemes, /candle/, participants often looked at it briefly before making a corrective saccade to fixate the piece of candy.When the cohort object was present on the table (Figure 3), participants made a brief saccade to it about 25% of the time before then making a corrective saccade to the target object.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Is the apple supposed to be put on the towel or into the box? At the moment when all the listener has heard so far is “Put the apple on the towel…”, there may be a temptation to interpret the extra towel in the visual display (top right of Figure 4) as the destination for the apple’s movement.",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "A completely different sensory system, vision, can influence the language system (see Figure 5).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith numerous effects of visual context on real-time language processing (Spivey, 2007), the schematic box-and-arrow models in Figure 2 might need to be enhanced with yet another arrow, connecting the visual system to the language system.Language Comprehension Influences Visual Perception\nEberhard et al.’s (1995) results of anticipatory reference resolution contributed to the evidence for predictive processing as a fundamental component in theories of real-time language comprehension (e.g., Elman, 1990; Dikker & Pylkkänen, 2013; Kamide, Altmann, & Haywood, 2003; Ryskin, Ng, Mimnaugh, Brown-Schmidt, & Federmeier, 2020) – even if these “predictions” may be nothing more than the emergent result of a multiscale pattern completion process (Falandays, Nguyen, & Spivey, 2021).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "With vision influencing language and language influencing vision (Anderson, Chiu, Huette & Spivey, 2011), perhaps it is worthwhile to slightly modify the schematic box-and-arrow diagram from Figure 5 with a bi-directional arrow connecting the visual system and the language system together (see Figure 6).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        },
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Although the progression from Figures 1, 2 and 5 to Figure 6 could give one the impression that we should take an existing model of language processing and an existing model of visual processing and simply connect them, that is surely not the optimal solution.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Importantly, as we continue to see arrows added to this old-fashioned diagram (e.g., Figure 6), it can start to look like the arrows might be “doing more work” than the boxes are (see Onnis & Spivey, 2012).",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith numerous effects of linguistic context on real-time visual processing (Spivey, 2007), the schematic box-and-arrow model in Figure 5 might need to update the arrow connecting the visual system and the language system to be bi-directional.Embodied Cognition\nWhen the arrows are explaining more of the phenomena than the boxes are, the late great Guy Van Orden referred to this as interaction-dominant dynamics (Van Orden, Holden, & Turvey, 2003).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "He contrasted it with the component-dominant dynamics of traditional linear feedforward modular models of cognition (recall Figure 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This is exactly what one would expect if the function of the language system was not isolable from the function of the visual system (e.g., Figure 6).",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Take, for example, the visual world paradigm experiment where participants were instructed to “Put the apple on the towel in the box” (Figure 4).",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "With such a tight relationship between language, vision and action, it should come as no surprise that we were able to replicate the eye movement results for spoken word recognition (Figure 3) and syntactic ambiguity resolution (Figure 4) with a computer-mouse movement task.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "For example, Figure 7 modifies Figure 6 by removing the pretense that language, vision and action processes have any kind of crisp discrete boundaries that delineate them from one another.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        },
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "There are still more coupling processes (i.e., arrows) internal to the language-like capacity in Figure 7 than there are coupling processes that connect it to the other capacities.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "The schematic diagram in Figure 7 can be softly assembled to reshape the system so that it is temporarily dedicated to one type of task or another.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "For instance, in Figure 8, the system has softly (temporarily) assembled itself into functioning mostly as a sensorimotor processing system by boosting the coupling of its vision and action processes and damping the coupling of the language processes.",
      "figure_references": [
        {
          "figure_number": "Figure 8",
          "panel": "",
          "figure_key": "figure_8"
        }
      ]
    },
    {
      "sentence": "Compare that soft assembly with the one in Figure 9, where the system has softly (temporarily) assembled itself into functioning mostly as a visuolinguistic processing system by boosting the coupling of some of its vision and language processes and damping the coupling of the action processes.",
      "figure_references": [
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "This schematic depiction of a soft-assembly might be for a cognitive system that is engaged in catching an American football while leaping in the air (or perhaps catching a bar of soap that’s trying to escape in the shower).Figure 9.",
      "figure_references": [
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "Rather than treating language as something for which the brain has dedicated processors that are hard-wired to function a certain way (e.g., Figure 1B), perhaps we should treat language as something that emerges from the self-organization capabilities of some brains-and-bodies performing actions together in a particular environment (e.g., Figure 7).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "Panel B",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "I have traced the epistemic progression from box-and-arrow diagrams of cognition that prevented context effects (Figure 1) to box-and-arrow diagrams that allow context effects (Figures 2, 5 and 6) and eventually to “arrows-and-arrows” diagrams that not only embrace context effects but even encourage the occasional blurring of the distinctions between traditional cognitive faculties (Figures 7–9).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This essay began by noting that box-and-arrow models have given way to “a few slightly different theoretical approaches that all readily incorporate immediate context effects.” Three of those theoretical approaches are worth noting here: Bayesian models, dynamical system theory, and artificial neural networks (Figure 10).",
      "figure_references": [
        {
          "figure_number": "Figure 10",
          "panel": "",
          "figure_key": "figure_10"
        },
        {
          "figure_number": "Figure 10",
          "panel": "",
          "figure_key": "figure_10"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nThese three slightly different theoretical frameworks operating at the cutting edge of contemporary cognitive science all can be seen as interactive frameworks that combine many contextual factors at once to convert sensory input into mental states and/or actions. (A) Bayesian approaches emphasize static internal mental representations that have probabilities associated with them. (B) Dynamical systems approaches emphasize temporally dynamic trajectories on a state-space manifold that may include both neural and non-neural parameters. (C) Neural network approaches emphasize roughly neurally plausible simulations of the relationships between sensory input, cognitive processes, and motor output.Rather than being adversaries, these different theoretical frameworks can, in principle, cooperate with one another in scientifically identifying the coherent bundle of internal causal forces that make a cognitive process warrant its own label (instead of relying on folk psychology), and also in determining how weakly or strongly one cognitive process influences another (see the bundles of arrows with labels in Figure 7).",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "Abstractly depicted at the top of Figure 11, we can imagine how individual minds (the pentagonal shapes) might fit together to form a social group.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "The pentagonal shapes at the social level of analysis (top of Figure 11) need not be made of smaller pentagonal shapes at the cognitive level; and those micro-pentagonal shapes wouldn’t need to be made of nano-pentagonal shapes at the neural level.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "Essentially, those “puzzle pieces” in Figure 11 had better be able to combine in ways that can indeed form one of those “asymmetric pentagons” above them.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "Essentially, if one’s theory says that the puzzle pieces in Figure 11 are made of sub-elements that do not look or behave at all like hexagons, then that theory about puzzle pieces might be impossible.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "And thus, as suggested back in Figure 7, perhaps our models (and even Figure 11 itself) should be made entirely of arrows (relations), with no closed polygons (objects) at all.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        },
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "However, they often made predictions that immediate context effects (e.g., color influencing motion perception or pragmatics influencing syntax) should be impossible (see Figure 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nIn the 1990s, the cognitive and neural sciences began reporting a wide variety of context effects suggesting that the subsystems in Figure 1 are not as modular as once thought.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "To examine spoken word recognition, we presented participants with a table containing small objects and toys (Figure 3) and gave them live spoken instructions (e.g., “Pick up the candy.”) while the headband-mounted eyetracker recorded their eye movements.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "A “cohort” refers to a word that shares several initial phonemes with the word that is being spoken (Marslen-Wilson, 1987). (Additional targets and cohorts included penny/pencil, car/carton, etc.)\nFigure 3.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith a display of several real objects on a table, a participant might be instructed to “Pick up the candy.” Since the object to the right of the candy has a typical name that uses the same first four phonemes, /candle/, participants often looked at it briefly before making a corrective saccade to fixate the piece of candy.When the cohort object was present on the table (Figure 3), participants made a brief saccade to it about 25% of the time before then making a corrective saccade to the target object.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Is the apple supposed to be put on the towel or into the box? At the moment when all the listener has heard so far is “Put the apple on the towel…”, there may be a temptation to interpret the extra towel in the visual display (top right of Figure 4) as the destination for the apple’s movement.",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "A completely different sensory system, vision, can influence the language system (see Figure 5).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith numerous effects of visual context on real-time language processing (Spivey, 2007), the schematic box-and-arrow models in Figure 2 might need to be enhanced with yet another arrow, connecting the visual system to the language system.Language Comprehension Influences Visual Perception\nEberhard et al.’s (1995) results of anticipatory reference resolution contributed to the evidence for predictive processing as a fundamental component in theories of real-time language comprehension (e.g., Elman, 1990; Dikker & Pylkkänen, 2013; Kamide, Altmann, & Haywood, 2003; Ryskin, Ng, Mimnaugh, Brown-Schmidt, & Federmeier, 2020) – even if these “predictions” may be nothing more than the emergent result of a multiscale pattern completion process (Falandays, Nguyen, & Spivey, 2021).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "With vision influencing language and language influencing vision (Anderson, Chiu, Huette & Spivey, 2011), perhaps it is worthwhile to slightly modify the schematic box-and-arrow diagram from Figure 5 with a bi-directional arrow connecting the visual system and the language system together (see Figure 6).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        },
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Although the progression from Figures 1, 2 and 5 to Figure 6 could give one the impression that we should take an existing model of language processing and an existing model of visual processing and simply connect them, that is surely not the optimal solution.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Importantly, as we continue to see arrows added to this old-fashioned diagram (e.g., Figure 6), it can start to look like the arrows might be “doing more work” than the boxes are (see Onnis & Spivey, 2012).",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith numerous effects of linguistic context on real-time visual processing (Spivey, 2007), the schematic box-and-arrow model in Figure 5 might need to update the arrow connecting the visual system and the language system to be bi-directional.Embodied Cognition\nWhen the arrows are explaining more of the phenomena than the boxes are, the late great Guy Van Orden referred to this as interaction-dominant dynamics (Van Orden, Holden, & Turvey, 2003).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "He contrasted it with the component-dominant dynamics of traditional linear feedforward modular models of cognition (recall Figure 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This is exactly what one would expect if the function of the language system was not isolable from the function of the visual system (e.g., Figure 6).",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Take, for example, the visual world paradigm experiment where participants were instructed to “Put the apple on the towel in the box” (Figure 4).",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "With such a tight relationship between language, vision and action, it should come as no surprise that we were able to replicate the eye movement results for spoken word recognition (Figure 3) and syntactic ambiguity resolution (Figure 4) with a computer-mouse movement task.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "For example, Figure 7 modifies Figure 6 by removing the pretense that language, vision and action processes have any kind of crisp discrete boundaries that delineate them from one another.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        },
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "There are still more coupling processes (i.e., arrows) internal to the language-like capacity in Figure 7 than there are coupling processes that connect it to the other capacities.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "The schematic diagram in Figure 7 can be softly assembled to reshape the system so that it is temporarily dedicated to one type of task or another.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "For instance, in Figure 8, the system has softly (temporarily) assembled itself into functioning mostly as a sensorimotor processing system by boosting the coupling of its vision and action processes and damping the coupling of the language processes.",
      "figure_references": [
        {
          "figure_number": "Figure 8",
          "panel": "",
          "figure_key": "figure_8"
        }
      ]
    },
    {
      "sentence": "Compare that soft assembly with the one in Figure 9, where the system has softly (temporarily) assembled itself into functioning mostly as a visuolinguistic processing system by boosting the coupling of some of its vision and language processes and damping the coupling of the action processes.",
      "figure_references": [
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "This schematic depiction of a soft-assembly might be for a cognitive system that is engaged in catching an American football while leaping in the air (or perhaps catching a bar of soap that’s trying to escape in the shower).Figure 9.",
      "figure_references": [
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "Rather than treating language as something for which the brain has dedicated processors that are hard-wired to function a certain way (e.g., Figure 1B), perhaps we should treat language as something that emerges from the self-organization capabilities of some brains-and-bodies performing actions together in a particular environment (e.g., Figure 7).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "Panel B",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "I have traced the epistemic progression from box-and-arrow diagrams of cognition that prevented context effects (Figure 1) to box-and-arrow diagrams that allow context effects (Figures 2, 5 and 6) and eventually to “arrows-and-arrows” diagrams that not only embrace context effects but even encourage the occasional blurring of the distinctions between traditional cognitive faculties (Figures 7–9).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This essay began by noting that box-and-arrow models have given way to “a few slightly different theoretical approaches that all readily incorporate immediate context effects.” Three of those theoretical approaches are worth noting here: Bayesian models, dynamical system theory, and artificial neural networks (Figure 10).",
      "figure_references": [
        {
          "figure_number": "Figure 10",
          "panel": "",
          "figure_key": "figure_10"
        },
        {
          "figure_number": "Figure 10",
          "panel": "",
          "figure_key": "figure_10"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nThese three slightly different theoretical frameworks operating at the cutting edge of contemporary cognitive science all can be seen as interactive frameworks that combine many contextual factors at once to convert sensory input into mental states and/or actions. (A) Bayesian approaches emphasize static internal mental representations that have probabilities associated with them. (B) Dynamical systems approaches emphasize temporally dynamic trajectories on a state-space manifold that may include both neural and non-neural parameters. (C) Neural network approaches emphasize roughly neurally plausible simulations of the relationships between sensory input, cognitive processes, and motor output.Rather than being adversaries, these different theoretical frameworks can, in principle, cooperate with one another in scientifically identifying the coherent bundle of internal causal forces that make a cognitive process warrant its own label (instead of relying on folk psychology), and also in determining how weakly or strongly one cognitive process influences another (see the bundles of arrows with labels in Figure 7).",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "Abstractly depicted at the top of Figure 11, we can imagine how individual minds (the pentagonal shapes) might fit together to form a social group.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "The pentagonal shapes at the social level of analysis (top of Figure 11) need not be made of smaller pentagonal shapes at the cognitive level; and those micro-pentagonal shapes wouldn’t need to be made of nano-pentagonal shapes at the neural level.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "Essentially, those “puzzle pieces” in Figure 11 had better be able to combine in ways that can indeed form one of those “asymmetric pentagons” above them.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "Essentially, if one’s theory says that the puzzle pieces in Figure 11 are made of sub-elements that do not look or behave at all like hexagons, then that theory about puzzle pieces might be impossible.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "And thus, as suggested back in Figure 7, perhaps our models (and even Figure 11 itself) should be made entirely of arrows (relations), with no closed polygons (objects) at all.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        },
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "However, they often made predictions that immediate context effects (e.g., color influencing motion perception or pragmatics influencing syntax) should be impossible (see Figure 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nIn the 1990s, the cognitive and neural sciences began reporting a wide variety of context effects suggesting that the subsystems in Figure 1 are not as modular as once thought.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "To examine spoken word recognition, we presented participants with a table containing small objects and toys (Figure 3) and gave them live spoken instructions (e.g., “Pick up the candy.”) while the headband-mounted eyetracker recorded their eye movements.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "A “cohort” refers to a word that shares several initial phonemes with the word that is being spoken (Marslen-Wilson, 1987). (Additional targets and cohorts included penny/pencil, car/carton, etc.)\nFigure 3.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith a display of several real objects on a table, a participant might be instructed to “Pick up the candy.” Since the object to the right of the candy has a typical name that uses the same first four phonemes, /candle/, participants often looked at it briefly before making a corrective saccade to fixate the piece of candy.When the cohort object was present on the table (Figure 3), participants made a brief saccade to it about 25% of the time before then making a corrective saccade to the target object.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Is the apple supposed to be put on the towel or into the box? At the moment when all the listener has heard so far is “Put the apple on the towel…”, there may be a temptation to interpret the extra towel in the visual display (top right of Figure 4) as the destination for the apple’s movement.",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "A completely different sensory system, vision, can influence the language system (see Figure 5).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith numerous effects of visual context on real-time language processing (Spivey, 2007), the schematic box-and-arrow models in Figure 2 might need to be enhanced with yet another arrow, connecting the visual system to the language system.Language Comprehension Influences Visual Perception\nEberhard et al.’s (1995) results of anticipatory reference resolution contributed to the evidence for predictive processing as a fundamental component in theories of real-time language comprehension (e.g., Elman, 1990; Dikker & Pylkkänen, 2013; Kamide, Altmann, & Haywood, 2003; Ryskin, Ng, Mimnaugh, Brown-Schmidt, & Federmeier, 2020) – even if these “predictions” may be nothing more than the emergent result of a multiscale pattern completion process (Falandays, Nguyen, & Spivey, 2021).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "With vision influencing language and language influencing vision (Anderson, Chiu, Huette & Spivey, 2011), perhaps it is worthwhile to slightly modify the schematic box-and-arrow diagram from Figure 5 with a bi-directional arrow connecting the visual system and the language system together (see Figure 6).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        },
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Although the progression from Figures 1, 2 and 5 to Figure 6 could give one the impression that we should take an existing model of language processing and an existing model of visual processing and simply connect them, that is surely not the optimal solution.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Importantly, as we continue to see arrows added to this old-fashioned diagram (e.g., Figure 6), it can start to look like the arrows might be “doing more work” than the boxes are (see Onnis & Spivey, 2012).",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith numerous effects of linguistic context on real-time visual processing (Spivey, 2007), the schematic box-and-arrow model in Figure 5 might need to update the arrow connecting the visual system and the language system to be bi-directional.Embodied Cognition\nWhen the arrows are explaining more of the phenomena than the boxes are, the late great Guy Van Orden referred to this as interaction-dominant dynamics (Van Orden, Holden, & Turvey, 2003).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "He contrasted it with the component-dominant dynamics of traditional linear feedforward modular models of cognition (recall Figure 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This is exactly what one would expect if the function of the language system was not isolable from the function of the visual system (e.g., Figure 6).",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Take, for example, the visual world paradigm experiment where participants were instructed to “Put the apple on the towel in the box” (Figure 4).",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "With such a tight relationship between language, vision and action, it should come as no surprise that we were able to replicate the eye movement results for spoken word recognition (Figure 3) and syntactic ambiguity resolution (Figure 4) with a computer-mouse movement task.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "For example, Figure 7 modifies Figure 6 by removing the pretense that language, vision and action processes have any kind of crisp discrete boundaries that delineate them from one another.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        },
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "There are still more coupling processes (i.e., arrows) internal to the language-like capacity in Figure 7 than there are coupling processes that connect it to the other capacities.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "The schematic diagram in Figure 7 can be softly assembled to reshape the system so that it is temporarily dedicated to one type of task or another.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "For instance, in Figure 8, the system has softly (temporarily) assembled itself into functioning mostly as a sensorimotor processing system by boosting the coupling of its vision and action processes and damping the coupling of the language processes.",
      "figure_references": [
        {
          "figure_number": "Figure 8",
          "panel": "",
          "figure_key": "figure_8"
        }
      ]
    },
    {
      "sentence": "Compare that soft assembly with the one in Figure 9, where the system has softly (temporarily) assembled itself into functioning mostly as a visuolinguistic processing system by boosting the coupling of some of its vision and language processes and damping the coupling of the action processes.",
      "figure_references": [
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "This schematic depiction of a soft-assembly might be for a cognitive system that is engaged in catching an American football while leaping in the air (or perhaps catching a bar of soap that’s trying to escape in the shower).Figure 9.",
      "figure_references": [
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "Rather than treating language as something for which the brain has dedicated processors that are hard-wired to function a certain way (e.g., Figure 1B), perhaps we should treat language as something that emerges from the self-organization capabilities of some brains-and-bodies performing actions together in a particular environment (e.g., Figure 7).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "Panel B",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "I have traced the epistemic progression from box-and-arrow diagrams of cognition that prevented context effects (Figure 1) to box-and-arrow diagrams that allow context effects (Figures 2, 5 and 6) and eventually to “arrows-and-arrows” diagrams that not only embrace context effects but even encourage the occasional blurring of the distinctions between traditional cognitive faculties (Figures 7–9).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This essay began by noting that box-and-arrow models have given way to “a few slightly different theoretical approaches that all readily incorporate immediate context effects.” Three of those theoretical approaches are worth noting here: Bayesian models, dynamical system theory, and artificial neural networks (Figure 10).",
      "figure_references": [
        {
          "figure_number": "Figure 10",
          "panel": "",
          "figure_key": "figure_10"
        },
        {
          "figure_number": "Figure 10",
          "panel": "",
          "figure_key": "figure_10"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nThese three slightly different theoretical frameworks operating at the cutting edge of contemporary cognitive science all can be seen as interactive frameworks that combine many contextual factors at once to convert sensory input into mental states and/or actions. (A) Bayesian approaches emphasize static internal mental representations that have probabilities associated with them. (B) Dynamical systems approaches emphasize temporally dynamic trajectories on a state-space manifold that may include both neural and non-neural parameters. (C) Neural network approaches emphasize roughly neurally plausible simulations of the relationships between sensory input, cognitive processes, and motor output.Rather than being adversaries, these different theoretical frameworks can, in principle, cooperate with one another in scientifically identifying the coherent bundle of internal causal forces that make a cognitive process warrant its own label (instead of relying on folk psychology), and also in determining how weakly or strongly one cognitive process influences another (see the bundles of arrows with labels in Figure 7).",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "Abstractly depicted at the top of Figure 11, we can imagine how individual minds (the pentagonal shapes) might fit together to form a social group.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "The pentagonal shapes at the social level of analysis (top of Figure 11) need not be made of smaller pentagonal shapes at the cognitive level; and those micro-pentagonal shapes wouldn’t need to be made of nano-pentagonal shapes at the neural level.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "Essentially, those “puzzle pieces” in Figure 11 had better be able to combine in ways that can indeed form one of those “asymmetric pentagons” above them.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "Essentially, if one’s theory says that the puzzle pieces in Figure 11 are made of sub-elements that do not look or behave at all like hexagons, then that theory about puzzle pieces might be impossible.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "And thus, as suggested back in Figure 7, perhaps our models (and even Figure 11 itself) should be made entirely of arrows (relations), with no closed polygons (objects) at all.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        },
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "However, they often made predictions that immediate context effects (e.g., color influencing motion perception or pragmatics influencing syntax) should be impossible (see Figure 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nIn the 1990s, the cognitive and neural sciences began reporting a wide variety of context effects suggesting that the subsystems in Figure 1 are not as modular as once thought.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "To examine spoken word recognition, we presented participants with a table containing small objects and toys (Figure 3) and gave them live spoken instructions (e.g., “Pick up the candy.”) while the headband-mounted eyetracker recorded their eye movements.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "A “cohort” refers to a word that shares several initial phonemes with the word that is being spoken (Marslen-Wilson, 1987). (Additional targets and cohorts included penny/pencil, car/carton, etc.)\nFigure 3.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith a display of several real objects on a table, a participant might be instructed to “Pick up the candy.” Since the object to the right of the candy has a typical name that uses the same first four phonemes, /candle/, participants often looked at it briefly before making a corrective saccade to fixate the piece of candy.When the cohort object was present on the table (Figure 3), participants made a brief saccade to it about 25% of the time before then making a corrective saccade to the target object.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Is the apple supposed to be put on the towel or into the box? At the moment when all the listener has heard so far is “Put the apple on the towel…”, there may be a temptation to interpret the extra towel in the visual display (top right of Figure 4) as the destination for the apple’s movement.",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "A completely different sensory system, vision, can influence the language system (see Figure 5).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith numerous effects of visual context on real-time language processing (Spivey, 2007), the schematic box-and-arrow models in Figure 2 might need to be enhanced with yet another arrow, connecting the visual system to the language system.Language Comprehension Influences Visual Perception\nEberhard et al.’s (1995) results of anticipatory reference resolution contributed to the evidence for predictive processing as a fundamental component in theories of real-time language comprehension (e.g., Elman, 1990; Dikker & Pylkkänen, 2013; Kamide, Altmann, & Haywood, 2003; Ryskin, Ng, Mimnaugh, Brown-Schmidt, & Federmeier, 2020) – even if these “predictions” may be nothing more than the emergent result of a multiscale pattern completion process (Falandays, Nguyen, & Spivey, 2021).",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "With vision influencing language and language influencing vision (Anderson, Chiu, Huette & Spivey, 2011), perhaps it is worthwhile to slightly modify the schematic box-and-arrow diagram from Figure 5 with a bi-directional arrow connecting the visual system and the language system together (see Figure 6).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        },
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Although the progression from Figures 1, 2 and 5 to Figure 6 could give one the impression that we should take an existing model of language processing and an existing model of visual processing and simply connect them, that is surely not the optimal solution.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Importantly, as we continue to see arrows added to this old-fashioned diagram (e.g., Figure 6), it can start to look like the arrows might be “doing more work” than the boxes are (see Onnis & Spivey, 2012).",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith numerous effects of linguistic context on real-time visual processing (Spivey, 2007), the schematic box-and-arrow model in Figure 5 might need to update the arrow connecting the visual system and the language system to be bi-directional.Embodied Cognition\nWhen the arrows are explaining more of the phenomena than the boxes are, the late great Guy Van Orden referred to this as interaction-dominant dynamics (Van Orden, Holden, & Turvey, 2003).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "He contrasted it with the component-dominant dynamics of traditional linear feedforward modular models of cognition (recall Figure 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This is exactly what one would expect if the function of the language system was not isolable from the function of the visual system (e.g., Figure 6).",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Take, for example, the visual world paradigm experiment where participants were instructed to “Put the apple on the towel in the box” (Figure 4).",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "With such a tight relationship between language, vision and action, it should come as no surprise that we were able to replicate the eye movement results for spoken word recognition (Figure 3) and syntactic ambiguity resolution (Figure 4) with a computer-mouse movement task.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "For example, Figure 7 modifies Figure 6 by removing the pretense that language, vision and action processes have any kind of crisp discrete boundaries that delineate them from one another.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        },
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "There are still more coupling processes (i.e., arrows) internal to the language-like capacity in Figure 7 than there are coupling processes that connect it to the other capacities.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "The schematic diagram in Figure 7 can be softly assembled to reshape the system so that it is temporarily dedicated to one type of task or another.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "For instance, in Figure 8, the system has softly (temporarily) assembled itself into functioning mostly as a sensorimotor processing system by boosting the coupling of its vision and action processes and damping the coupling of the language processes.",
      "figure_references": [
        {
          "figure_number": "Figure 8",
          "panel": "",
          "figure_key": "figure_8"
        }
      ]
    },
    {
      "sentence": "Compare that soft assembly with the one in Figure 9, where the system has softly (temporarily) assembled itself into functioning mostly as a visuolinguistic processing system by boosting the coupling of some of its vision and language processes and damping the coupling of the action processes.",
      "figure_references": [
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "This schematic depiction of a soft-assembly might be for a cognitive system that is engaged in catching an American football while leaping in the air (or perhaps catching a bar of soap that’s trying to escape in the shower).Figure 9.",
      "figure_references": [
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "Rather than treating language as something for which the brain has dedicated processors that are hard-wired to function a certain way (e.g., Figure 1B), perhaps we should treat language as something that emerges from the self-organization capabilities of some brains-and-bodies performing actions together in a particular environment (e.g., Figure 7).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "Panel B",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "I have traced the epistemic progression from box-and-arrow diagrams of cognition that prevented context effects (Figure 1) to box-and-arrow diagrams that allow context effects (Figures 2, 5 and 6) and eventually to “arrows-and-arrows” diagrams that not only embrace context effects but even encourage the occasional blurring of the distinctions between traditional cognitive faculties (Figures 7–9).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This essay began by noting that box-and-arrow models have given way to “a few slightly different theoretical approaches that all readily incorporate immediate context effects.” Three of those theoretical approaches are worth noting here: Bayesian models, dynamical system theory, and artificial neural networks (Figure 10).",
      "figure_references": [
        {
          "figure_number": "Figure 10",
          "panel": "",
          "figure_key": "figure_10"
        },
        {
          "figure_number": "Figure 10",
          "panel": "",
          "figure_key": "figure_10"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nThese three slightly different theoretical frameworks operating at the cutting edge of contemporary cognitive science all can be seen as interactive frameworks that combine many contextual factors at once to convert sensory input into mental states and/or actions. (A) Bayesian approaches emphasize static internal mental representations that have probabilities associated with them. (B) Dynamical systems approaches emphasize temporally dynamic trajectories on a state-space manifold that may include both neural and non-neural parameters. (C) Neural network approaches emphasize roughly neurally plausible simulations of the relationships between sensory input, cognitive processes, and motor output.Rather than being adversaries, these different theoretical frameworks can, in principle, cooperate with one another in scientifically identifying the coherent bundle of internal causal forces that make a cognitive process warrant its own label (instead of relying on folk psychology), and also in determining how weakly or strongly one cognitive process influences another (see the bundles of arrows with labels in Figure 7).",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "Abstractly depicted at the top of Figure 11, we can imagine how individual minds (the pentagonal shapes) might fit together to form a social group.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "The pentagonal shapes at the social level of analysis (top of Figure 11) need not be made of smaller pentagonal shapes at the cognitive level; and those micro-pentagonal shapes wouldn’t need to be made of nano-pentagonal shapes at the neural level.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "Essentially, those “puzzle pieces” in Figure 11 had better be able to combine in ways that can indeed form one of those “asymmetric pentagons” above them.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "Essentially, if one’s theory says that the puzzle pieces in Figure 11 are made of sub-elements that do not look or behave at all like hexagons, then that theory about puzzle pieces might be impossible.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "And thus, as suggested back in Figure 7, perhaps our models (and even Figure 11 itself) should be made entirely of arrows (relations), with no closed polygons (objects) at all.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        },
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "However, they often made predictions that immediate context effects (e.g., color influencing motion perception or pragmatics influencing syntax) should be impossible (see Figure 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nIn the 1990s, the cognitive and neural sciences began reporting a wide variety of context effects suggesting that the subsystems in Figure 1 are not as modular as once thought.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "However, they often made predictions that immediate context effects (e.g., color influencing motion perception or pragmatics influencing syntax) should be impossible (see Figure 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "In the 1990s, the cognitive and neural sciences began reporting a wide variety of context effects suggesting that the subsystems in Figure 1 are not as modular as once thought.",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "To examine spoken word recognition, we presented participants with a table containing small objects and toys (Figure 3) and gave them live spoken instructions (e.g., “Pick up the candy.”) while the headband-mounted eyetracker recorded their eye movements.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "A “cohort” refers to a word that shares several initial phonemes with the word that is being spoken (Marslen-Wilson, 1987). (Additional targets and cohorts included penny/pencil, car/carton, etc.)\nFigure 3.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith a display of several real objects on a table, a participant might be instructed to “Pick up the candy.” Since the object to the right of the candy has a typical name that uses the same first four phonemes, /candle/, participants often looked at it briefly before making a corrective saccade to fixate the piece of candy.When the cohort object was present on the table (Figure 3), participants made a brief saccade to it about 25% of the time before then making a corrective saccade to the target object.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Is the apple supposed to be put on the towel or into the box? At the moment when all the listener has heard so far is “Put the apple on the towel…”, there may be a temptation to interpret the extra towel in the visual display (top right of Figure 4) as the destination for the apple’s movement.",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "A completely different sensory system, vision, can influence the language system (see Figure 5).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith numerous effects of visual context on real-time language processing (Spivey, 2007), the schematic box-and-arrow models in Figure 2 might need to be enhanced with yet another arrow, connecting the visual system to the language system.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "To examine spoken word recognition, we presented participants with a table containing small objects and toys (Figure 3) and gave them live spoken instructions (e.g., “Pick up the candy.”) while the headband-mounted eyetracker recorded their eye movements.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "When the cohort object was present on the table (Figure 3), participants made a brief saccade to it about 25% of the time before then making a corrective saccade to the target object.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        }
      ]
    },
    {
      "sentence": "Is the apple supposed to be put on the towel or into the box? At the moment when all the listener has heard so far is “Put the apple on the towel…”, there may be a temptation to interpret the extra towel in the visual display (top right of Figure 4) as the destination for the apple’s movement.",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "A completely different sensory system, vision, can influence the language system (see Figure 5).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "With numerous effects of visual context on real-time language processing (Spivey, 2007), the schematic box-and-arrow models in Figure 2 might need to be enhanced with yet another arrow, connecting the visual system to the language system.",
      "figure_references": [
        {
          "figure_number": "Figure 2",
          "panel": "",
          "figure_key": "figure_2"
        }
      ]
    },
    {
      "sentence": "With vision influencing language and language influencing vision (Anderson, Chiu, Huette & Spivey, 2011), perhaps it is worthwhile to slightly modify the schematic box-and-arrow diagram from Figure 5 with a bi-directional arrow connecting the visual system and the language system together (see Figure 6).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        },
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Although the progression from Figures 1, 2 and 5 to Figure 6 could give one the impression that we should take an existing model of language processing and an existing model of visual processing and simply connect them, that is surely not the optimal solution.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Importantly, as we continue to see arrows added to this old-fashioned diagram (e.g., Figure 6), it can start to look like the arrows might be “doing more work” than the boxes are (see Onnis & Spivey, 2012).",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nWith numerous effects of linguistic context on real-time visual processing (Spivey, 2007), the schematic box-and-arrow model in Figure 5 might need to update the arrow connecting the visual system and the language system to be bi-directional.",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "With vision influencing language and language influencing vision (Anderson, Chiu, Huette & Spivey, 2011), perhaps it is worthwhile to slightly modify the schematic box-and-arrow diagram from Figure 5 with a bi-directional arrow connecting the visual system and the language system together (see Figure 6).",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        },
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Although the progression from Figures 1, 2 and 5 to Figure 6 could give one the impression that we should take an existing model of language processing and an existing model of visual processing and simply connect them, that is surely not the optimal solution.",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Importantly, as we continue to see arrows added to this old-fashioned diagram (e.g., Figure 6), it can start to look like the arrows might be “doing more work” than the boxes are (see Onnis & Spivey, 2012).",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "With numerous effects of linguistic context on real-time visual processing (Spivey, 2007), the schematic box-and-arrow model in Figure 5 might need to update the arrow connecting the visual system and the language system to be bi-directional.",
      "figure_references": [
        {
          "figure_number": "Figure 5",
          "panel": "",
          "figure_key": "figure_5"
        }
      ]
    },
    {
      "sentence": "He contrasted it with the component-dominant dynamics of traditional linear feedforward modular models of cognition (recall Figure 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This is exactly what one would expect if the function of the language system was not isolable from the function of the visual system (e.g., Figure 6).",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Take, for example, the visual world paradigm experiment where participants were instructed to “Put the apple on the towel in the box” (Figure 4).",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "With such a tight relationship between language, vision and action, it should come as no surprise that we were able to replicate the eye movement results for spoken word recognition (Figure 3) and syntactic ambiguity resolution (Figure 4) with a computer-mouse movement task.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "For example, Figure 7 modifies Figure 6 by removing the pretense that language, vision and action processes have any kind of crisp discrete boundaries that delineate them from one another.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        },
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "There are still more coupling processes (i.e., arrows) internal to the language-like capacity in Figure 7 than there are coupling processes that connect it to the other capacities.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "The schematic diagram in Figure 7 can be softly assembled to reshape the system so that it is temporarily dedicated to one type of task or another.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "For instance, in Figure 8, the system has softly (temporarily) assembled itself into functioning mostly as a sensorimotor processing system by boosting the coupling of its vision and action processes and damping the coupling of the language processes.",
      "figure_references": [
        {
          "figure_number": "Figure 8",
          "panel": "",
          "figure_key": "figure_8"
        }
      ]
    },
    {
      "sentence": "Compare that soft assembly with the one in Figure 9, where the system has softly (temporarily) assembled itself into functioning mostly as a visuolinguistic processing system by boosting the coupling of some of its vision and language processes and damping the coupling of the action processes.",
      "figure_references": [
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "This schematic depiction of a soft-assembly might be for a cognitive system that is engaged in catching an American football while leaping in the air (or perhaps catching a bar of soap that’s trying to escape in the shower).Figure 9.",
      "figure_references": [
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "He contrasted it with the component-dominant dynamics of traditional linear feedforward modular models of cognition (recall Figure 1).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This is exactly what one would expect if the function of the language system was not isolable from the function of the visual system (e.g., Figure 6).",
      "figure_references": [
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "Take, for example, the visual world paradigm experiment where participants were instructed to “Put the apple on the towel in the box” (Figure 4).",
      "figure_references": [
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "With such a tight relationship between language, vision and action, it should come as no surprise that we were able to replicate the eye movement results for spoken word recognition (Figure 3) and syntactic ambiguity resolution (Figure 4) with a computer-mouse movement task.",
      "figure_references": [
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        },
        {
          "figure_number": "Figure 3",
          "panel": "",
          "figure_key": "figure_3"
        },
        {
          "figure_number": "Figure 4",
          "panel": "",
          "figure_key": "figure_4"
        }
      ]
    },
    {
      "sentence": "For example, Figure 7 modifies Figure 6 by removing the pretense that language, vision and action processes have any kind of crisp discrete boundaries that delineate them from one another.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        },
        {
          "figure_number": "Figure 6",
          "panel": "",
          "figure_key": "figure_6"
        }
      ]
    },
    {
      "sentence": "There are still more coupling processes (i.e., arrows) internal to the language-like capacity in Figure 7 than there are coupling processes that connect it to the other capacities.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "The schematic diagram in Figure 7 can be softly assembled to reshape the system so that it is temporarily dedicated to one type of task or another.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "For instance, in Figure 8, the system has softly (temporarily) assembled itself into functioning mostly as a sensorimotor processing system by boosting the coupling of its vision and action processes and damping the coupling of the language processes.",
      "figure_references": [
        {
          "figure_number": "Figure 8",
          "panel": "",
          "figure_key": "figure_8"
        }
      ]
    },
    {
      "sentence": "Compare that soft assembly with the one in Figure 9, where the system has softly (temporarily) assembled itself into functioning mostly as a visuolinguistic processing system by boosting the coupling of some of its vision and language processes and damping the coupling of the action processes.",
      "figure_references": [
        {
          "figure_number": "Figure 9",
          "panel": "",
          "figure_key": "figure_9"
        }
      ]
    },
    {
      "sentence": "Rather than treating language as something for which the brain has dedicated processors that are hard-wired to function a certain way (e.g., Figure 1B), perhaps we should treat language as something that emerges from the self-organization capabilities of some brains-and-bodies performing actions together in a particular environment (e.g., Figure 7).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "Panel B",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "Rather than treating language as something for which the brain has dedicated processors that are hard-wired to function a certain way (e.g., Figure 1B), perhaps we should treat language as something that emerges from the self-organization capabilities of some brains-and-bodies performing actions together in a particular environment (e.g., Figure 7).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "Panel B",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "I have traced the epistemic progression from box-and-arrow diagrams of cognition that prevented context effects (Figure 1) to box-and-arrow diagrams that allow context effects (Figures 2, 5 and 6) and eventually to “arrows-and-arrows” diagrams that not only embrace context effects but even encourage the occasional blurring of the distinctions between traditional cognitive faculties (Figures 7–9).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This essay began by noting that box-and-arrow models have given way to “a few slightly different theoretical approaches that all readily incorporate immediate context effects.” Three of those theoretical approaches are worth noting here: Bayesian models, dynamical system theory, and artificial neural networks (Figure 10).",
      "figure_references": [
        {
          "figure_number": "Figure 10",
          "panel": "",
          "figure_key": "figure_10"
        },
        {
          "figure_number": "Figure 10",
          "panel": "",
          "figure_key": "figure_10"
        }
      ]
    },
    {
      "sentence": "Open in a new tab\nThese three slightly different theoretical frameworks operating at the cutting edge of contemporary cognitive science all can be seen as interactive frameworks that combine many contextual factors at once to convert sensory input into mental states and/or actions. (A) Bayesian approaches emphasize static internal mental representations that have probabilities associated with them. (B) Dynamical systems approaches emphasize temporally dynamic trajectories on a state-space manifold that may include both neural and non-neural parameters. (C) Neural network approaches emphasize roughly neurally plausible simulations of the relationships between sensory input, cognitive processes, and motor output.Rather than being adversaries, these different theoretical frameworks can, in principle, cooperate with one another in scientifically identifying the coherent bundle of internal causal forces that make a cognitive process warrant its own label (instead of relying on folk psychology), and also in determining how weakly or strongly one cognitive process influences another (see the bundles of arrows with labels in Figure 7).",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "Abstractly depicted at the top of Figure 11, we can imagine how individual minds (the pentagonal shapes) might fit together to form a social group.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "The pentagonal shapes at the social level of analysis (top of Figure 11) need not be made of smaller pentagonal shapes at the cognitive level; and those micro-pentagonal shapes wouldn’t need to be made of nano-pentagonal shapes at the neural level.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "Essentially, those “puzzle pieces” in Figure 11 had better be able to combine in ways that can indeed form one of those “asymmetric pentagons” above them.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "Essentially, if one’s theory says that the puzzle pieces in Figure 11 are made of sub-elements that do not look or behave at all like hexagons, then that theory about puzzle pieces might be impossible.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "And thus, as suggested back in Figure 7, perhaps our models (and even Figure 11 itself) should be made entirely of arrows (relations), with no closed polygons (objects) at all.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        },
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "I have traced the epistemic progression from box-and-arrow diagrams of cognition that prevented context effects (Figure 1) to box-and-arrow diagrams that allow context effects (Figures 2, 5 and 6) and eventually to “arrows-and-arrows” diagrams that not only embrace context effects but even encourage the occasional blurring of the distinctions between traditional cognitive faculties (Figures 7–9).",
      "figure_references": [
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        },
        {
          "figure_number": "Figure 1",
          "panel": "",
          "figure_key": "figure_1"
        }
      ]
    },
    {
      "sentence": "This essay began by noting that box-and-arrow models have given way to “a few slightly different theoretical approaches that all readily incorporate immediate context effects.” Three of those theoretical approaches are worth noting here: Bayesian models, dynamical system theory, and artificial neural networks (Figure 10).",
      "figure_references": [
        {
          "figure_number": "Figure 10",
          "panel": "",
          "figure_key": "figure_10"
        },
        {
          "figure_number": "Figure 10",
          "panel": "",
          "figure_key": "figure_10"
        }
      ]
    },
    {
      "sentence": "Rather than being adversaries, these different theoretical frameworks can, in principle, cooperate with one another in scientifically identifying the coherent bundle of internal causal forces that make a cognitive process warrant its own label (instead of relying on folk psychology), and also in determining how weakly or strongly one cognitive process influences another (see the bundles of arrows with labels in Figure 7).",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        }
      ]
    },
    {
      "sentence": "Abstractly depicted at the top of Figure 11, we can imagine how individual minds (the pentagonal shapes) might fit together to form a social group.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "The pentagonal shapes at the social level of analysis (top of Figure 11) need not be made of smaller pentagonal shapes at the cognitive level; and those micro-pentagonal shapes wouldn’t need to be made of nano-pentagonal shapes at the neural level.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "Essentially, those “puzzle pieces” in Figure 11 had better be able to combine in ways that can indeed form one of those “asymmetric pentagons” above them.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "Essentially, if one’s theory says that the puzzle pieces in Figure 11 are made of sub-elements that do not look or behave at all like hexagons, then that theory about puzzle pieces might be impossible.",
      "figure_references": [
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    },
    {
      "sentence": "And thus, as suggested back in Figure 7, perhaps our models (and even Figure 11 itself) should be made entirely of arrows (relations), with no closed polygons (objects) at all.",
      "figure_references": [
        {
          "figure_number": "Figure 7",
          "panel": "",
          "figure_key": "figure_7"
        },
        {
          "figure_number": "Figure 11",
          "panel": "",
          "figure_key": "figure_11"
        }
      ]
    }
  ],
  "extraction_stats": {
    "figures_count": 9,
    "claims_count": 308,
    "images_downloaded": 9,
    "tables_filtered": 290
  }
}