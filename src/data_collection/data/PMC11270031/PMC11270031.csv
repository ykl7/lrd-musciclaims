paper_id,claim,figure_id,title,caption,local_image_path,url
PMC11270031,"A total of 6,299 citations were found (see Figure 1 for a flow chart of the systematic search process).",PMC11270031_figure_1,Figure 1.,PRISMA flow chart of the systematic review process.,./data/PMC11270031/images/figure_1.jpg,https://cdn.ncbi.nlm.nih.gov/pmc/blobs/4414/11270031/eef296fc4124/fpsyg-15-1428732-g001.jpg
PMC11270031,"Of these studies, 12 were selected for inclusion (see Figure 1 for reasons for exclusion).",PMC11270031_figure_1,Figure 1.,PRISMA flow chart of the systematic review process.,./data/PMC11270031/images/figure_1.jpg,https://cdn.ncbi.nlm.nih.gov/pmc/blobs/4414/11270031/eef296fc4124/fpsyg-15-1428732-g001.jpg
PMC11270031,"Each of the study effect sizes is shown in Table 2, and a forest plot is in Figure 2.",PMC11270031_figure_2,Figure 2.,Forest plot of effect sizes.,./data/PMC11270031/images/figure_2.jpg,https://cdn.ncbi.nlm.nih.gov/pmc/blobs/4414/11270031/06fc335b0397/fpsyg-15-1428732-g002.jpg
PMC11270031,"Study, learning style group, condition (if more than one), measure (if more than one), subgroups (if any)


Number of participants


Hedges’ g


Variance of Hedges’ g





Aslaksen and Lorås (2019), auditory
9
−1.25
0.44



Aslaksen and Lorås (2019), visual
13
0.85
0.30



Burns (n.d.), auditory
7
−0.10
0.04



Burns (n.d.), visual
30
0.44
0.01



Chen (2020), auditory
41
−0.08
0.09



Chen (2020), read/write
34
0.26
0.11



Chui et al. (

2021)

, auditory

9
1.56
0.09



Chui et al. (

2021)

, visual

9
0.61
0.04



Chen and Sun (

2012)

, verbal, interaction comparison

73
0.11
0.06



Chen and Sun (

2012)

, visualizer, interactive treatment

66
0.08
0.07



Cuevas and Dawson (2018), auditory
118
−2.87
0.07



Cuevas and Dawson (2018), visual
65
2.13
0.10



Ge (2021), auditory
76
−0.74
0.06



Ge (2021), visual
64
1.20
0.07



Hazra et al. (2013), verbal, engineering comprehension
15
−0.41
0.24



Hazra et al. (

2013)

, verbal, history comprehension

0.06
0.24



Hazra et al. (2013), verbal, engineering recall
−0.21
0.24



Hazra et al. (

2013)

, verbal, history recall

0.13
0.24



Hazra et al. (2013), verbal, engineering recognition
−0.44
0.24



Hazra et al. (

2013)

, verbal, history recognition

0.46
0.24



Hazra et al. (2013), verbal, engineering transfer
0.10
0.24



Hazra et al. (

2013)

, verbal, history transfer

0.04
0.24



Hazra et al. (2013), visual, engineering comprehension
124
−0.10
0.03



Hazra et al. (

2013)

, visual, history comprehension

0.43
0.03



Hazra et al. (2013), visual, engineering recall
0.00
0.03



Hazra et al. (

2013)

, visual, history recall

0.25
0.03



Hazra et al. (2013), visual, engineering recognition
0.19
0.03



Hazra et al. (

2013)

, visual, history recognition

0.30
0.03



Hazra et al. (2013), visual, engineering transfer
−0.04
0.03



Hazra et al. (

2013)

, visual, history transfer

0.16
0.03



Kam et al. (

2020)

, auditory

29
0.76
0.14



Kam et al. (

2020)

, visual

31
0.79
0.13



Kassaian (

2007)

, auditory, week 1

29
0.78
0.02



Kassaian (

2007)

, auditory, week 2

0.77
0.02



Kassaian (

2007)

, visual, week 1

37
0.80
0.01



Kassaian (

2007)

, visual, week 2

0.64
0.02



Lehmann and Seufert (

2020)

, auditory comprehension

21
0.26
0.18



Lehmann and Seufert (2020), auditory recall
−0.11
0.18



Lehmann and Seufert (

2020)

, visual comprehension

21
1.04
0.20



Lehmann and Seufert (2020), visual recall
0.86
0.19



Moser and Zumbach (2018), verbalizer VVQ
42
0.45
0.09



Moser and Zumbach (2018), verbalizer SBLSQ
40
0.61
0.10



Moser and Zumbach (2018), visualizer VVQ
82
−0.03
0.05



Moser and Zumbach (2018), visualizer SBLSQ
73
−0.04
0.05



Moussa-Inaty et al. (2019), auditory
31
−0.25
0.12



Moussa-Inaty et al. (2019), visual
30
0.39
0.13



Mujtaba et al. (2022), auditory OPT delayed
40
1.40
0.12



Mujtaba et al. (2022), auditory OPT post
1.35
0.12



Mujtaba et al. (2022), auditory WT delayed
1.73
0.13



Mujtaba et al. (2022), auditory WT post
1.36
0.12



Mujtaba et al. (2022), visual OPT delayed
40
−0.53
0.10



Mujtaba et al. (2022), visual OPT post
−0.56
0.10



Mujtaba et al. (2022), visual WT delayed
−0.59
0.10



Mujtaba et al. (2022), visual WT post
−0.63
0.10



Papanagnou et al. (2016), auditory
52
−0.07
0.34



Papanagnou et al. (2016), kinesthetic
62
0.52
0.07



Papanagnou et al. (2016), visual
48
−0.27
0.08



Rassaei (2018), auditory delayed production
32
2.58
0.22



Rassaei (2018), auditory delayed recognition
2.14
0.19



Rassaei (2018), auditory post production
2.02
0.18



Rassaei (2018), auditory post recognition

1.88
0.17



Rassaei (2018), visual delayed production
30
−1.47
0.16



Rassaei (2018), visual delayed recognition

−1.23
0.15



Rassaei (2018), visual post production
−1.48
0.16



Rassaei (2018), visual post recognition
−1.35
0.16



Rassaei (2019), auditory delayed OPT
31
1.59
0.16



Rassaei (2019), auditory post OPT

1.72
0.17



Rassaei (2019), auditory delayed WT

1.69
0.17



Rassaei (2019), auditory post WT

1.77
0.17



Rassaei (2019), read/write delayed OPT
30
−0.34
0.13



Rassaei (2019), read/write post OPT

−0.04
0.13



Rassaei (2019), read/write delayed WT

−0.04
0.13



Rassaei (2019), read/write post WT

−0.28
0.13



Riding and Douglas (1993), verbalizer, analytic subgroup explanation
10
−0.70
0.35



Riding and Douglas (1993), verbalizer, analytic subgroup labelling
0.12
0.33



Riding and Douglas (1993), verbalizer, analytic subgroup problem solving
0.08
0.33



Riding and Douglas (1993), verbalizer, analytic subgroup short recall
−1.20
0.40



Riding and Douglas (1993), verbalizer, wholist subgroup, explanation
10
−0.15
0.33



Riding and Douglas (1993), verbalizer, wholist subgroup, labeling
−0.11
0.33



Riding and Douglas (1993), verbalizer, wholist subgroup, problem solving
 
−0.37
0.33



Riding and Douglas (1993), verbalizer, wholist subgroup, short recall
−0.17
0.33



Riding and Douglas (1993), visualizer, analytic subgroup explanation
10
1.51
0.44



Riding and Douglas (1993), visualizer, analytic subgroup labeling

1.33
0.41



Riding and Douglas (1993), visualizer, analytic subgroup problem solving

1.08
0.38



Riding and Douglas (1993), visualizer, analytic subgroup short recall

0.50
0.34



Riding and Douglas (1993), visualizer, wholist subgroup, explanation
10
1.11
0.39



Riding and Douglas (1993), visualizer, wholist subgroup, labeling

1.05
0.38



Riding and Douglas (1993), visualizer, wholist subgroup, problem solving

1.30
0.41



Riding and Douglas (1993), visualizer, wholist subgroup, short recall

1.35
0.42



Rogowsky et al. (2015), auditory time one
21
−0.25
0.18



Rogowsky et al. (2015), auditory time two
−0.24
0.18



Rogowsky et al. (2015), visual time one
20
−0.11
0.18



Rogowsky et al. (2015), visual time two
−0.20
0.18



Rogowsky et al. (2020) auditory
12
0.17
0.03



Rogowsky et al. (2020) visual
22
−0.12
0.02



Tadayonifar et al. (

2021)

, auditory

7
2.03
0.16



Tadayonifar et al. (

2021)

, read/write

6
2.63
0.27



Open in a new tab
Learning outcomes indicating a crossover effect as articulated in Pashler et al. (2008) in which at least two styles had higher learning outcomes with matched instruction are bolded.Figure 2.",PMC11270031_figure_2,Figure 2.,Forest plot of effect sizes.,./data/PMC11270031/images/figure_2.jpg,https://cdn.ncbi.nlm.nih.gov/pmc/blobs/4414/11270031/06fc335b0397/fpsyg-15-1428732-g002.jpg
PMC11270031,"A funnel plot was generated using the “metafor” package in R (Viechtbauer, 2010; see Figure 3).",PMC11270031_figure_3,Figure 3.,Funnel plot of effect sizes.,./data/PMC11270031/images/figure_3.jpg,https://cdn.ncbi.nlm.nih.gov/pmc/blobs/4414/11270031/18e5f1d0e54a/fpsyg-15-1428732-g003.jpg
PMC11270031,"As indicated in Figure 1, five that had their full texts screened did not have sufficient statistics to calculate the effect sizes reported.",PMC11270031_figure_1,Figure 1.,PRISMA flow chart of the systematic review process.,./data/PMC11270031/images/figure_1.jpg,https://cdn.ncbi.nlm.nih.gov/pmc/blobs/4414/11270031/eef296fc4124/fpsyg-15-1428732-g001.jpg
